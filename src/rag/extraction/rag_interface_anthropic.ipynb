{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:28:00,284 - INFO - Cargando base de datos vectorial desde c:\\Users\\Usuario\\Documents\\Github\\Seguridad económica\\src\\rag\\models\\indexes\\chroma_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando interfaz de consola...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:28:00,577 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-04-01 12:28:00,766 - INFO - Colecciones disponibles: ['bibliography']\n",
      "2025-04-01 12:28:00,771 - INFO - Colección 'bibliography' cargada exitosamente\n",
      "2025-04-01 12:28:00,771 - INFO - Buscando: '¿Cuáles son las principales dependencias de Europa en materias primas críticas?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consulta de prueba: ¿Cuáles son las principales dependencias de Europa en materias primas críticas?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot open header file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 386\u001b[0m\n\u001b[0;32m    383\u001b[0m test_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Cuáles son las principales dependencias de Europa en materias primas críticas?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConsulta de prueba: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 386\u001b[0m answer, context, results \u001b[38;5;241m=\u001b[39m rag_query(test_query, collection)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESPUESTA:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 247\u001b[0m, in \u001b[0;36mrag_query\u001b[1;34m(query, db_collection, n_results, modelo)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03mRealiza el proceso completo de RAG: recuperación + generación.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    Respuesta generada, contexto y resultados de búsqueda\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Buscar documentos relevantes\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m search_results \u001b[38;5;241m=\u001b[39m search_database(db_collection, query, n_results)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Formatear el contexto\u001b[39;00m\n\u001b[0;32m    250\u001b[0m context \u001b[38;5;241m=\u001b[39m format_context(search_results)\n",
      "Cell \u001b[1;32mIn[1], line 148\u001b[0m, in \u001b[0;36msearch_database\u001b[1;34m(collection, query, n_results)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03mRealiza una búsqueda semántica en la base de datos.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Diccionario con los resultados de la búsqueda\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuscando: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m results \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    149\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[0;32m    150\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results\n\u001b[0;32m    151\u001b[0m )\n\u001b[0;32m    153\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSe encontraron \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documentos relevantes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:222\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    211\u001b[0m query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_query_request(\n\u001b[0;32m    212\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[0;32m    213\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m    220\u001b[0m )\n\u001b[1;32m--> 222\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_query(\n\u001b[0;32m    223\u001b[0m     collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    224\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    225\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_results\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    226\u001b[0m     where\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    227\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere_document\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    228\u001b[0m     include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    229\u001b[0m     tenant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant,\n\u001b[0;32m    230\u001b[0m     database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    235\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m action(retry_state)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: rs\u001b[38;5;241m.\u001b[39moutcome\u001b[38;5;241m.\u001b[39mresult())\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\api\\segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limit_enforcer\u001b[38;5;241m.\u001b[39mrate_limit(func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\rate_limit\\simple_rate_limit\\__init__.py:24\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\api\\segment.py:816\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[1;34m(self, collection_id, query_embeddings, n_results, where, where_document, include, tenant, database)\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dimension(scan\u001b[38;5;241m.\u001b[39mcollection, \u001b[38;5;28mlen\u001b[39m(embedding), update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quota_enforcer\u001b[38;5;241m.\u001b[39menforce(\n\u001b[0;32m    808\u001b[0m     action\u001b[38;5;241m=\u001b[39mAction\u001b[38;5;241m.\u001b[39mQUERY,\n\u001b[0;32m    809\u001b[0m     tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    813\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[0;32m    814\u001b[0m )\n\u001b[1;32m--> 816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mknn(\n\u001b[0;32m    817\u001b[0m     KNNPlan(\n\u001b[0;32m    818\u001b[0m         scan,\n\u001b[0;32m    819\u001b[0m         KNN(query_embeddings, n_results),\n\u001b[0;32m    820\u001b[0m         Filter(\u001b[38;5;28;01mNone\u001b[39;00m, where, where_document),\n\u001b[0;32m    821\u001b[0m         Projection(\n\u001b[0;32m    822\u001b[0m             IncludeEnum\u001b[38;5;241m.\u001b[39mdocuments \u001b[38;5;129;01min\u001b[39;00m include,\n\u001b[0;32m    823\u001b[0m             IncludeEnum\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;129;01min\u001b[39;00m include,\n\u001b[0;32m    824\u001b[0m             IncludeEnum\u001b[38;5;241m.\u001b[39mmetadatas \u001b[38;5;129;01min\u001b[39;00m include,\n\u001b[0;32m    825\u001b[0m             IncludeEnum\u001b[38;5;241m.\u001b[39mdistances \u001b[38;5;129;01min\u001b[39;00m include,\n\u001b[0;32m    826\u001b[0m             IncludeEnum\u001b[38;5;241m.\u001b[39muris \u001b[38;5;129;01min\u001b[39;00m include,\n\u001b[0;32m    827\u001b[0m         ),\n\u001b[0;32m    828\u001b[0m     )\n\u001b[0;32m    829\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\execution\\executor\\local.py:135\u001b[0m, in \u001b[0;36mLocalExecutor.knn\u001b[1;34m(self, plan)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefiltered_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prefiltered_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    127\u001b[0m     query \u001b[38;5;241m=\u001b[39m VectorQuery(\n\u001b[0;32m    128\u001b[0m         vectors\u001b[38;5;241m=\u001b[39mplan\u001b[38;5;241m.\u001b[39mknn\u001b[38;5;241m.\u001b[39membeddings,\n\u001b[0;32m    129\u001b[0m         k\u001b[38;5;241m=\u001b[39mplan\u001b[38;5;241m.\u001b[39mknn\u001b[38;5;241m.\u001b[39mfetch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         request_version_context\u001b[38;5;241m=\u001b[39mplan\u001b[38;5;241m.\u001b[39mscan\u001b[38;5;241m.\u001b[39mversion,\n\u001b[0;32m    134\u001b[0m     )\n\u001b[1;32m--> 135\u001b[0m     knns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_segment(plan\u001b[38;5;241m.\u001b[39mscan\u001b[38;5;241m.\u001b[39mcollection)\u001b[38;5;241m.\u001b[39mquery_vectors(query)\n\u001b[0;32m    137\u001b[0m ids \u001b[38;5;241m=\u001b[39m [[r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m knns]\n\u001b[0;32m    138\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\execution\\executor\\local.py:205\u001b[0m, in \u001b[0;36mLocalExecutor._vector_segment\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_vector_segment\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection: Collection) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VectorReader:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mget_segment(collection\u001b[38;5;241m.\u001b[39mid, VectorReader)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\segment\\impl\\manager\\local.py:217\u001b[0m, in \u001b[0;36mLocalSegmentManager.get_segment\u001b[1;34m(self, collection_id, type)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Instances must be atomically created, so we use a lock to ensure that only one thread\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# creates the instance.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 217\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance(segment)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(S, instance)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\segment\\impl\\manager\\local.py:246\u001b[0m, in \u001b[0;36mLocalSegmentManager._instance\u001b[1;34m(self, segment)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m segment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instances:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cls(segment)\n\u001b[1;32m--> 246\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system, segment)\n\u001b[0;32m    247\u001b[0m     instance\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instances[segment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m instance\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_persistent_hnsw.py:128\u001b[0m, in \u001b[0;36mPersistentLocalHnswSegment.__init__\u001b[1;34m(self, system, segment)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_to_label) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dimensionality \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dimensionality)\n\u001b[1;32m--> 128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dimensionality)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persist_data \u001b[38;5;241m=\u001b[39m PersistentData(\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dimensionality,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_elements_added,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_to_seq_id,\n\u001b[0;32m    136\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_persistent_hnsw.py:208\u001b[0m, in \u001b[0;36mPersistentLocalHnswSegment._init_index\u001b[1;34m(self, dimensionality)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Check if index exists and load it if it does\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_exists():\n\u001b[1;32m--> 208\u001b[0m     index\u001b[38;5;241m.\u001b[39mload_index(\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_storage_folder(),\n\u001b[0;32m    210\u001b[0m         is_persistent_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    211\u001b[0m         max_elements\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\n\u001b[0;32m    212\u001b[0m             \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    213\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount(\n\u001b[0;32m    214\u001b[0m                     request_version_context\u001b[38;5;241m=\u001b[39mRequestVersionContext(\n\u001b[0;32m    215\u001b[0m                         collection_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, log_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    216\u001b[0m                     )\n\u001b[0;32m    217\u001b[0m                 )\n\u001b[0;32m    218\u001b[0m                 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mresize_factor,\n\u001b[0;32m    219\u001b[0m                 DEFAULT_CAPACITY,\n\u001b[0;32m    220\u001b[0m             )\n\u001b[0;32m    221\u001b[0m         ),\n\u001b[0;32m    222\u001b[0m     )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     index\u001b[38;5;241m.\u001b[39minit_index(\n\u001b[0;32m    225\u001b[0m         max_elements\u001b[38;5;241m=\u001b[39mDEFAULT_CAPACITY,\n\u001b[0;32m    226\u001b[0m         ef_construction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mconstruction_ef,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m         persistence_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_storage_folder(),\n\u001b[0;32m    230\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot open header file"
     ]
    }
   ],
   "source": [
    "# Notebook: rag_interface_anthropic.ipynb\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Importar las bibliotecas necesarias\n",
    "try:\n",
    "    import chromadb\n",
    "    CHROMADB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CHROMADB_AVAILABLE = False\n",
    "    logger.error(\"chromadb no está instalado. Necesario para la base de datos vectorial.\")\n",
    "\n",
    "try:\n",
    "    from anthropic import Anthropic\n",
    "    ANTHROPIC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ANTHROPIC_AVAILABLE = False\n",
    "    logger.error(\"anthropic no está instalado. Necesario para interactuar con el modelo Claude. Ejecuta 'pip install anthropic'\")\n",
    "\n",
    "# Configuración de Anthropic (usar una variable de entorno o configurar directamente)\n",
    "# Si tienes una clave API, configúrala así:\n",
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\n",
    "\n",
    "def recreate_collection_from_embeddings(client, collection_name: str) -> Any:\n",
    "    \"\"\"\n",
    "    Recrea una colección en ChromaDB usando los embeddings guardados previamente.\n",
    "    \n",
    "    Args:\n",
    "        client: Cliente de ChromaDB\n",
    "        collection_name: Nombre de la colección a crear\n",
    "        \n",
    "    Returns:\n",
    "        Objeto de colección de ChromaDB\n",
    "    \"\"\"\n",
    "    # Definir rutas a los archivos de embeddings\n",
    "    current_dir = pathlib.Path(os.getcwd())\n",
    "    embeddings_dir = os.path.join(current_dir.parent, \"models\", \"embeddings\")\n",
    "    embeddings_path = os.path.join(embeddings_dir, \"all-MiniLM-L6-v2_embeddings.npy\")\n",
    "    metadata_path = os.path.join(embeddings_dir, \"all-MiniLM-L6-v2_metadata.json\")\n",
    "    \n",
    "    # Cargar embeddings y metadatos\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Eliminar la colección si ya existe\n",
    "    try:\n",
    "        client.delete_collection(name=collection_name)\n",
    "        logger.info(f\"Colección existente '{collection_name}' eliminada\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Crear nueva colección\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    logger.info(f\"Nueva colección '{collection_name}' creada\")\n",
    "    \n",
    "    # Añadir documentos en lotes\n",
    "    batch_size = 500\n",
    "    total_docs = len(metadata[\"texts\"])\n",
    "    ids = [f\"chunk_{i}\" for i in range(total_docs)]\n",
    "    \n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        end = min(i + batch_size, total_docs)\n",
    "        \n",
    "        # Preparar lote\n",
    "        batch_ids = ids[i:end]\n",
    "        batch_texts = metadata[\"texts\"][i:end]\n",
    "        batch_embeddings = embeddings[i:end].tolist()\n",
    "        batch_metadatas = metadata[\"metadatas\"][i:end]\n",
    "        \n",
    "        # Añadir a la colección\n",
    "        collection.add(\n",
    "            embeddings=batch_embeddings,\n",
    "            documents=batch_texts,\n",
    "            metadatas=batch_metadatas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Añadidos documentos {i+1} a {end} de {total_docs}\")\n",
    "    \n",
    "    logger.info(f\"Colección recreada con {total_docs} documentos\")\n",
    "    return collection\n",
    "\n",
    "def load_vector_database(db_path: str, collection_name: str = \"bibliography\") -> Any:\n",
    "    \"\"\"\n",
    "    Carga la base de datos vectorial.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Ruta a la base de datos ChromaDB\n",
    "        collection_name: Nombre de la colección a cargar\n",
    "        \n",
    "    Returns:\n",
    "        Objeto de colección de ChromaDB\n",
    "    \"\"\"\n",
    "    if not CHROMADB_AVAILABLE:\n",
    "        raise ImportError(\"chromadb es necesario para cargar la base de datos vectorial.\")\n",
    "    \n",
    "    logger.info(f\"Cargando base de datos vectorial desde {db_path}\")\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    \n",
    "    # Verificar si la colección existe\n",
    "    try:\n",
    "        # En ChromaDB 0.6.3, list_collections devuelve solo nombres\n",
    "        collection_names = client.list_collections()\n",
    "        logger.info(f\"Colecciones disponibles: {collection_names}\")\n",
    "        \n",
    "        if collection_name in collection_names:\n",
    "            # Obtener la colección por nombre\n",
    "            collection = client.get_collection(name=collection_name)\n",
    "            logger.info(f\"Colección '{collection_name}' cargada exitosamente\")\n",
    "            return collection\n",
    "        else:\n",
    "            raise ValueError(f\"La colección '{collection_name}' no existe en la base de datos\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al cargar la colección: {e}\")\n",
    "        \n",
    "        # Si hay algún problema, recrear la colección usando los embeddings existentes\n",
    "        logger.info(\"Recreando la colección desde los embeddings guardados...\")\n",
    "        return recreate_collection_from_embeddings(client, collection_name)\n",
    "\n",
    "\n",
    "def search_database(collection, query: str, n_results: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda semántica en la base de datos.\n",
    "    \n",
    "    Args:\n",
    "        collection: Colección de ChromaDB\n",
    "        query: Consulta del usuario\n",
    "        n_results: Número de resultados a devolver\n",
    "        \n",
    "    Returns:\n",
    "        Diccionario con los resultados de la búsqueda\n",
    "    \"\"\"\n",
    "    logger.info(f\"Buscando: '{query}'\")\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Se encontraron {len(results['documents'][0])} documentos relevantes\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def format_context(search_results: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Formatea los resultados de búsqueda en un contexto para el modelo de lenguaje.\n",
    "    \n",
    "    Args:\n",
    "        search_results: Resultados de la búsqueda\n",
    "        \n",
    "    Returns:\n",
    "        Contexto formateado\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    \n",
    "    documents = search_results['documents'][0]\n",
    "    metadatas = search_results['metadatas'][0]\n",
    "    \n",
    "    for i, (doc, meta) in enumerate(zip(documents, metadatas)):\n",
    "        source = meta.get('source', 'Desconocido')\n",
    "        document = meta.get('document', 'Documento sin nombre')\n",
    "        context += f\"\\n\\nDocumento {i+1} (Fuente: {source}, Referencia: {document}):\\n{doc}\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def generate_answer_anthropic(query: str, context: str, modelo: str = \"claude-3-5-sonnet-20240620\") -> str:\n",
    "    \"\"\"\n",
    "    Genera una respuesta utilizando Anthropic Claude con el contexto recuperado.\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta del usuario\n",
    "        context: Contexto extraído de la base de conocimiento\n",
    "        modelo: Modelo de Claude a utilizar\n",
    "        \n",
    "    Returns:\n",
    "        Respuesta generada\n",
    "    \"\"\"\n",
    "    if not ANTHROPIC_AVAILABLE:\n",
    "        raise ImportError(\"anthropic no está instalado. Ejecuta 'pip install anthropic' para usar Claude.\")\n",
    "    \n",
    "    # Crear cliente Anthropic\n",
    "    anthropic_client = Anthropic(api_key=os.environ.get(\"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\"))\n",
    "    \n",
    "    logger.info(f\"Generando respuesta con el modelo {modelo}\")\n",
    "    \n",
    "    # Crear el mensaje para Claude\n",
    "    mensaje = f\"\"\"\n",
    "    <instrucciones>\n",
    "    Eres un asistente especializado en dependencias económicas y sus implicaciones geopolíticas.\n",
    "    Responde a las preguntas basándote ÚNICAMENTE en la información proporcionada en el contexto.\n",
    "    Si la información no está en el contexto, di que no tienes suficiente información para responder.\n",
    "    Cita las fuentes específicas (autores y año) al proporcionar información.\n",
    "    Responde en el mismo idioma en que se formula la pregunta.\n",
    "    Tus respuestas deben ser precisas, objetivas y basadas en evidencia.\n",
    "    </instrucciones>\n",
    "    \n",
    "    <contexto>\n",
    "    {context}\n",
    "    </contexto>\n",
    "    \n",
    "    <pregunta>\n",
    "    {query}\n",
    "    </pregunta>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamar a la API de Anthropic\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=modelo,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": mensaje}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "\n",
    "def rag_query(query: str, db_collection, n_results: int = 5, modelo: str = \"claude-3-5-sonnet-20240620\") -> tuple:\n",
    "    \"\"\"\n",
    "    Realiza el proceso completo de RAG: recuperación + generación.\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta del usuario\n",
    "        db_collection: Colección de ChromaDB\n",
    "        n_results: Número de fragmentos relevantes a recuperar\n",
    "        modelo: Modelo de Claude a utilizar\n",
    "        \n",
    "    Returns:\n",
    "        Respuesta generada, contexto y resultados de búsqueda\n",
    "    \"\"\"\n",
    "    # Buscar documentos relevantes\n",
    "    search_results = search_database(db_collection, query, n_results)\n",
    "    \n",
    "    # Formatear el contexto\n",
    "    context = format_context(search_results)\n",
    "    \n",
    "    # Generar respuesta\n",
    "    answer = generate_answer_anthropic(query, context, modelo)\n",
    "    \n",
    "    return answer, context, search_results\n",
    "\n",
    "\n",
    "# Configuración para una interfaz interactiva básica\n",
    "def interactive_rag():\n",
    "    \"\"\"\n",
    "    Proporciona una interfaz interactiva para consultar el sistema RAG.\n",
    "    \"\"\"\n",
    "    # Definir rutas\n",
    "    current_dir = pathlib.Path(os.getcwd())\n",
    "    db_dir = os.path.join(current_dir.parent, \"models\", \"indexes\", \"chroma_db\")\n",
    "    \n",
    "    # Cargar la base de datos\n",
    "    try:\n",
    "        collection = load_vector_database(db_dir, \"bibliography\")\n",
    "        print(\"Base de datos cargada exitosamente.\")\n",
    "        print(\"Escribe 'salir' para terminar.\")\n",
    "        \n",
    "        while True:\n",
    "            query = input(\"\\nPregunta: \")\n",
    "            \n",
    "            if query.lower() in [\"salir\", \"exit\", \"quit\", \"q\"]:\n",
    "                print(\"¡Hasta luego!\")\n",
    "                break\n",
    "            \n",
    "            if not query.strip():\n",
    "                continue\n",
    "            \n",
    "            print(\"Buscando información relevante...\")\n",
    "            answer, context, results = rag_query(query, collection)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"RESPUESTA:\")\n",
    "            print(answer)\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Opcionalmente, mostrar las fuentes\n",
    "            show_sources = input(\"\\n¿Mostrar fuentes utilizadas? (s/n): \").lower()\n",
    "            if show_sources.startswith(\"s\"):\n",
    "                print(\"\\nFUENTES UTILIZADAS:\")\n",
    "                for i, meta in enumerate(results['metadatas'][0]):\n",
    "                    print(f\"{i+1}. {meta.get('source', 'Desconocido')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en la interfaz interactiva: {e}\")\n",
    "        print(f\"Ocurrió un error: {e}\")\n",
    "\n",
    "\n",
    "# Si quieres usar una interfaz gráfica con Gradio\n",
    "def create_gradio_interface():\n",
    "    \"\"\"\n",
    "    Crea una interfaz gráfica con Gradio para consultar el sistema RAG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import gradio as gr\n",
    "        \n",
    "        # Definir rutas\n",
    "        current_dir = pathlib.Path(os.getcwd())\n",
    "        db_dir = os.path.join(current_dir.parent, \"models\", \"indexes\", \"chroma_db\")\n",
    "        \n",
    "        # Cargar la base de datos\n",
    "        collection = load_vector_database(db_dir, \"bibliography\")\n",
    "        \n",
    "        def process_query(query, num_results=5):\n",
    "            answer, context, results = rag_query(query, collection, n_results=num_results)\n",
    "            \n",
    "            # Formatear las fuentes\n",
    "            sources = []\n",
    "            for meta in results['metadatas'][0]:\n",
    "                source = meta.get('source', 'Desconocido')\n",
    "                document = meta.get('document', 'Documento sin nombre')\n",
    "                sources.append(f\"{source} ({document})\")\n",
    "            \n",
    "            sources_text = \"Fuentes consultadas:\\n\" + \"\\n\".join([f\"- {s}\" for s in sources])\n",
    "            \n",
    "            return answer, sources_text\n",
    "        \n",
    "        # Crear la interfaz\n",
    "        with gr.Blocks(title=\"Chatbot Bibliográfico\") as demo:\n",
    "            gr.Markdown(\"# Chatbot Bibliográfico Especializado\")\n",
    "            gr.Markdown(\"Consulta información sobre dependencias económicas y sus implicaciones geopolíticas\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    query_input = gr.Textbox(label=\"Tu pregunta\", lines=2, placeholder=\"Escribe tu pregunta aquí...\")\n",
    "                    num_results = gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Número de fuentes a consultar\")\n",
    "                    submit_btn = gr.Button(\"Consultar\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    answer_output = gr.Textbox(label=\"Respuesta\", lines=15)\n",
    "                    sources_output = gr.Textbox(label=\"Fuentes utilizadas\", lines=5)\n",
    "            \n",
    "            submit_btn.click(\n",
    "                fn=process_query,\n",
    "                inputs=[query_input, num_results],\n",
    "                outputs=[answer_output, sources_output]\n",
    "            )\n",
    "        \n",
    "        # Lanzar la interfaz\n",
    "        demo.launch(share=True)\n",
    "        \n",
    "    except ImportError:\n",
    "        logger.error(\"Gradio no está instalado. Ejecuta 'pip install gradio' para usar la interfaz gráfica.\")\n",
    "        print(\"Gradio no está instalado. Ejecuta 'pip install gradio' para usar la interfaz gráfica.\")\n",
    "        \n",
    "        # Ejecutar versión de consola como alternativa\n",
    "        interactive_rag()\n",
    "\n",
    "\n",
    "# Verificar que Anthropic API key está configurada\n",
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "    api_key = input(\"Introduce tu Anthropic API Key: \")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = api_key\n",
    "    \n",
    "# Preguntar qué interfaz usar\n",
    "interface_choice = input(\"¿Qué tipo de interfaz deseas usar? (consola/gradio): \").lower()\n",
    "\n",
    "if interface_choice.startswith(\"g\"):\n",
    "    print(\"Iniciando interfaz gráfica con Gradio...\")\n",
    "    create_gradio_interface()\n",
    "else:\n",
    "    print(\"Iniciando interfaz de consola...\")\n",
    "    # Cargar la base de datos\n",
    "    current_dir = pathlib.Path(os.getcwd())\n",
    "    db_dir = os.path.join(current_dir.parent, \"models\", \"indexes\", \"chroma_db\")\n",
    "    collection = load_vector_database(db_dir, \"bibliography\")\n",
    "    \n",
    "    # Ejecutar consulta de prueba\n",
    "    test_query = \"¿Cuáles son las principales dependencias de Europa en materias primas críticas?\"\n",
    "    print(f\"\\nConsulta de prueba: {test_query}\")\n",
    "    \n",
    "    answer, context, results = rag_query(test_query, collection)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESPUESTA:\")\n",
    "    print(answer)\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Iniciar interfaz interactiva\n",
    "    interactive_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:57:09,396 - INFO - Versión de ChromaDB: 0.6.3\n",
      "2025-04-01 12:57:09,446 - INFO - Creando nueva base de datos en c:\\Users\\Usuario\\Documents\\Github\\Seguridad económica\\src\\rag\\models\\indexes\\chroma_db_new\n",
      "2025-04-01 12:57:09,446 - INFO - Eliminando base de datos existente en c:\\Users\\Usuario\\Documents\\Github\\Seguridad económica\\src\\rag\\models\\indexes\\chroma_db_new\n",
      "2025-04-01 12:57:09,454 - INFO - Base de datos anterior eliminada correctamente\n",
      "2025-04-01 12:57:09,455 - INFO - Cargando embeddings desde c:\\Users\\Usuario\\Documents\\Github\\Seguridad económica\\src\\rag\\models\\embeddings\\all-MiniLM-L6-v2_embeddings.npy\n",
      "2025-04-01 12:57:09,460 - INFO - Cargando metadatos desde c:\\Users\\Usuario\\Documents\\Github\\Seguridad económica\\src\\rag\\models\\embeddings\\all-MiniLM-L6-v2_metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando nueva base de datos vectorial a partir de los embeddings existentes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:57:09,786 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-04-01 12:57:10,236 - INFO - Colección 'bibliography' creada\n",
      "2025-04-01 12:57:10,777 - INFO - Añadidos documentos 1 a 500 de 6625\n",
      "2025-04-01 12:57:11,304 - INFO - Añadidos documentos 501 a 1000 de 6625\n",
      "2025-04-01 12:57:11,861 - INFO - Añadidos documentos 1001 a 1500 de 6625\n",
      "2025-04-01 12:57:12,421 - INFO - Añadidos documentos 1501 a 2000 de 6625\n",
      "2025-04-01 12:57:13,018 - INFO - Añadidos documentos 2001 a 2500 de 6625\n",
      "2025-04-01 12:57:13,561 - INFO - Añadidos documentos 2501 a 3000 de 6625\n",
      "2025-04-01 12:57:14,187 - INFO - Añadidos documentos 3001 a 3500 de 6625\n",
      "2025-04-01 12:57:14,731 - INFO - Añadidos documentos 3501 a 4000 de 6625\n",
      "2025-04-01 12:57:15,531 - INFO - Añadidos documentos 4001 a 4500 de 6625\n",
      "2025-04-01 12:57:16,084 - INFO - Añadidos documentos 4501 a 5000 de 6625\n",
      "2025-04-01 12:57:16,763 - INFO - Añadidos documentos 5001 a 5500 de 6625\n",
      "2025-04-01 12:57:17,318 - INFO - Añadidos documentos 5501 a 6000 de 6625\n",
      "2025-04-01 12:57:17,962 - INFO - Añadidos documentos 6001 a 6500 de 6625\n",
      "2025-04-01 12:57:18,135 - INFO - Añadidos documentos 6501 a 6625 de 6625\n",
      "2025-04-01 12:57:18,135 - INFO - Base de datos creada exitosamente con 6625 documentos\n",
      "2025-04-01 12:57:18,141 - INFO - Buscando: '¿Cuáles son las principales dependencias de Europa en materias primas críticas?'\n",
      "2025-04-01 12:57:18,336 - INFO - Se encontraron 5 documentos relevantes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando interfaz de consola...\n",
      "\n",
      "Consulta de prueba: ¿Cuáles son las principales dependencias de Europa en materias primas críticas?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:57:18,336 - INFO - Cargando modelo desde C:\\Users\\Usuario\\.lmstudio\\models\\lmstudio-community\\Mistral-7B-Instruct-v0.3-GGUF\\Mistral-7B-Instruct-v0.3-Q4_K_M.gguf\n",
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\dependencias\\Lib\\site-packages\\llama_cpp\\llama.py:1240: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESPUESTA:\n",
      "\n",
      "La información proporcionada no especifica explícitamente cuáles son las principales dependencias de Europa en materias primas críticas. Sin embargo, se menciona en los documentos 2 y 3 que se está realizando un estudio sobre la lista de materias primas críticas de la UE (Documento 2: 27 European Commission: Study on the EU's list of Critical Raw Materials, 2020 y Documento 3: European Commission: Study on the EU's list of Critical Raw Materials, 2020). Estos documentos también mencionan que el análisis se centra en las dependencias en materias primas, pero no se proporciona una lista específica de materias primas críticas en estos documentos.\n",
      "\n",
      "Para obtener más información sobre las dependencias de Europa en materias primas críticas, es recomendable revisar el estudio mencionado en los documentos 2 y 3.\n",
      "\n",
      "Referencias:\n",
      "\n",
      "* Comission swd-strategic-dependencies-capacities_en 2021\n",
      "* EC_Strategic Dependencies 2022\n",
      "================================================================================\n",
      "Sistema RAG listo para consultas.\n",
      "Escribe 'salir' para terminar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 13:03:56,302 - INFO - Buscando: 'Me gustaría que resumieras los tipos de estudios que tratan de analizar la dependencia de importaciones de los países'\n",
      "2025-04-01 13:03:56,348 - INFO - Se encontraron 5 documentos relevantes\n",
      "2025-04-01 13:03:56,349 - INFO - Cargando modelo desde C:\\Users\\Usuario\\.lmstudio\\models\\lmstudio-community\\Mistral-7B-Instruct-v0.3-GGUF\\Mistral-7B-Instruct-v0.3-Q4_K_M.gguf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando información relevante...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESPUESTA:\n",
      "Los estudios que tratan de analizar la dependencia de importaciones de los países se enfocan en dos áreas principales:\n",
      "\n",
      "1. La concentración de las importaciones en unos pocos proveedores externos y su impacto en los precios de importación (Irina Balteanu, Katja Schmidt y Francesca Viani, 2025).\n",
      "2. La utilización de la análisis de redes para describir y comprender las interdependencias provenientes de las relaciones comerciales bilaterales y el análisis de flujos comerciales en varias dimensiones (Benedictis, 2014).\n",
      "\n",
      "En ambos casos, se busca comprender cómo la concentración de las importaciones puede afectar al precio que un país paga por sus importaciones y cómo las relaciones comerciales pueden influenciar en las interdependencias entre países. Sin embargo, hay limitaciones en el análisis de dependencias en productos específicos o de alta tecnología, en servicios y en el análisis de tendencias cambiantes o emergentes (EC_Strategic Dependencies, 2022).\n",
      "================================================================================\n",
      "\n",
      "FUENTES UTILIZADAS:\n",
      "1. Irina Balteanu, Katja Schmidt and Francesca Viani 2025.txt\n",
      "2. Irina Balteanu, Katja Schmidt and Francesca Viani 2025.txt\n",
      "3. Irina Balteanu, Katja Schmidt and Francesca Viani 2025.txt\n",
      "4. Benedictis, 2014.txt\n",
      "5. EC_Strategic Dependencies 2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Notebook: rag_interface_local_model.ipynb\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Importar las bibliotecas necesarias\n",
    "try:\n",
    "    import chromadb\n",
    "    CHROMADB_AVAILABLE = True\n",
    "    logger.info(f\"Versión de ChromaDB: {chromadb.__version__}\")\n",
    "except ImportError:\n",
    "    CHROMADB_AVAILABLE = False\n",
    "    logger.error(\"chromadb no está instalado. Necesario para la base de datos vectorial.\")\n",
    "\n",
    "try:\n",
    "    from llama_cpp import Llama\n",
    "    LLAMA_CPP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LLAMA_CPP_AVAILABLE = False\n",
    "    logger.error(\"llama-cpp-python no está instalado. Ejecuta 'pip install llama-cpp-python'\")\n",
    "\n",
    "# Función para crear una base de datos limpia a partir de los embeddings guardados\n",
    "def create_fresh_db(embeddings_path: str, metadata_path: str, db_dir: str, collection_name: str = \"bibliography\"):\n",
    "    \"\"\"\n",
    "    Crea una base de datos completamente nueva usando los embeddings existentes.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creando nueva base de datos en {db_dir}\")\n",
    "    \n",
    "    # Eliminar la base de datos anterior si existe\n",
    "    import shutil\n",
    "    if os.path.exists(db_dir):\n",
    "        logger.info(f\"Eliminando base de datos existente en {db_dir}\")\n",
    "        try:\n",
    "            shutil.rmtree(db_dir)\n",
    "            logger.info(\"Base de datos anterior eliminada correctamente\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"No se pudo eliminar completamente la base de datos anterior: {e}\")\n",
    "    \n",
    "    # Crear el directorio para la nueva base de datos\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "    \n",
    "    # Cargar embeddings y metadatos\n",
    "    logger.info(f\"Cargando embeddings desde {embeddings_path}\")\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    \n",
    "    logger.info(f\"Cargando metadatos desde {metadata_path}\")\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Crear cliente y colección\n",
    "    client = chromadb.PersistentClient(path=db_dir)\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    logger.info(f\"Colección '{collection_name}' creada\")\n",
    "    \n",
    "    # Añadir documentos en lotes para evitar problemas de memoria\n",
    "    batch_size = 500\n",
    "    total_docs = len(metadata[\"texts\"])\n",
    "    ids = [f\"chunk_{i}\" for i in range(total_docs)]\n",
    "    \n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        end = min(i + batch_size, total_docs)\n",
    "        \n",
    "        # Preparar lote\n",
    "        batch_ids = ids[i:end]\n",
    "        batch_texts = metadata[\"texts\"][i:end]\n",
    "        batch_embeddings = embeddings[i:end].tolist()\n",
    "        batch_metadatas = metadata[\"metadatas\"][i:end]\n",
    "        \n",
    "        # Añadir a la colección\n",
    "        collection.add(\n",
    "            embeddings=batch_embeddings,\n",
    "            documents=batch_texts,\n",
    "            metadatas=batch_metadatas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Añadidos documentos {i+1} a {end} de {total_docs}\")\n",
    "    \n",
    "    logger.info(f\"Base de datos creada exitosamente con {total_docs} documentos\")\n",
    "    return collection\n",
    "\n",
    "\n",
    "def search_database(collection, query: str, n_results: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda semántica en la base de datos.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Buscando: '{query}'\")\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Se encontraron {len(results['documents'][0])} documentos relevantes\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def format_context(search_results: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Formatea los resultados de búsqueda en un contexto para el modelo de lenguaje.\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    \n",
    "    documents = search_results['documents'][0]\n",
    "    metadatas = search_results['metadatas'][0]\n",
    "    \n",
    "    for i, (doc, meta) in enumerate(zip(documents, metadatas)):\n",
    "        source = meta.get('source', 'Desconocido')\n",
    "        document = meta.get('document', 'Documento sin nombre')\n",
    "        context += f\"\\n\\nDocumento {i+1} (Fuente: {source}, Referencia: {document}):\\n{doc}\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def generate_answer_local(query: str, context: str, model_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Genera una respuesta utilizando un modelo local con llama-cpp-python.\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta del usuario\n",
    "        context: Contexto extraído de la base de conocimiento\n",
    "        model_path: Ruta al archivo del modelo\n",
    "        \n",
    "    Returns:\n",
    "        Respuesta generada\n",
    "    \"\"\"\n",
    "    if not LLAMA_CPP_AVAILABLE:\n",
    "        raise ImportError(\"llama-cpp-python no está instalado. Ejecuta 'pip install llama-cpp-python'\")\n",
    "    \n",
    "    logger.info(f\"Cargando modelo desde {model_path}\")\n",
    "    \n",
    "    # Crear la plantilla del prompt para el modelo\n",
    "    prompt = f\"\"\"<s>[INST] Eres un asistente especializado en dependencias económicas y sus implicaciones geopolíticas.\n",
    "Responde a las preguntas basándote ÚNICAMENTE en la información proporcionada en el contexto.\n",
    "Si la información no está en el contexto, di que no tienes suficiente información para responder.\n",
    "Cita las fuentes específicas (autores y año) al proporcionar información.\n",
    "Responde en el mismo idioma en que se formula la pregunta.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {query} [/INST]\n",
    "\"\"\"\n",
    "    \n",
    "    # Inicializar el modelo\n",
    "    # Nota: El parámetro n_gpu_layers determina cuántas capas se cargan en la GPU\n",
    "    llm = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=4096,          # Contexto máximo\n",
    "        n_gpu_layers=-1,     # Usar todas las capas posibles en GPU\n",
    "        verbose=False        # No mostrar logs detallados\n",
    "    )\n",
    "    \n",
    "    # Generar respuesta\n",
    "    output = llm(\n",
    "        prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "        stop=[\"</s>\"]  # Token de parada para Mistral\n",
    "    )\n",
    "    \n",
    "    # Extraer solo la respuesta generada\n",
    "    response = output[\"choices\"][0][\"text\"]\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def rag_query(query: str, db_collection, n_results: int = 5, model_path: str = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Realiza el proceso completo de RAG: recuperación + generación.\n",
    "    \"\"\"\n",
    "    # Buscar documentos relevantes\n",
    "    search_results = search_database(db_collection, query, n_results)\n",
    "    \n",
    "    # Formatear el contexto\n",
    "    context = format_context(search_results)\n",
    "    \n",
    "    # Generar respuesta\n",
    "    answer = generate_answer_local(query, context, model_path)\n",
    "    \n",
    "    return answer, context, search_results\n",
    "\n",
    "\n",
    "# Configuración para una interfaz interactiva básica\n",
    "def interactive_rag(collection, model_path):\n",
    "    \"\"\"\n",
    "    Proporciona una interfaz interactiva para consultar el sistema RAG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Sistema RAG listo para consultas.\")\n",
    "        print(\"Escribe 'salir' para terminar.\")\n",
    "        \n",
    "        while True:\n",
    "            query = input(\"\\nPregunta: \")\n",
    "            \n",
    "            if query.lower() in [\"salir\", \"exit\", \"quit\", \"q\"]:\n",
    "                print(\"¡Hasta luego!\")\n",
    "                break\n",
    "            \n",
    "            if not query.strip():\n",
    "                continue\n",
    "            \n",
    "            print(\"Buscando información relevante...\")\n",
    "            answer, context, results = rag_query(query, collection, model_path=model_path)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"RESPUESTA:\")\n",
    "            print(answer)\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Opcionalmente, mostrar las fuentes\n",
    "            show_sources = input(\"\\n¿Mostrar fuentes utilizadas? (s/n): \").lower()\n",
    "            if show_sources.startswith(\"s\"):\n",
    "                print(\"\\nFUENTES UTILIZADAS:\")\n",
    "                for i, meta in enumerate(results['metadatas'][0]):\n",
    "                    print(f\"{i+1}. {meta.get('source', 'Desconocido')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en la interfaz interactiva: {e}\")\n",
    "        print(f\"Ocurrió un error: {e}\")\n",
    "\n",
    "\n",
    "# Definir rutas y configuración\n",
    "current_dir = pathlib.Path(os.getcwd())\n",
    "embeddings_dir = os.path.join(current_dir.parent, \"models\", \"embeddings\")\n",
    "embeddings_path = os.path.join(embeddings_dir, \"all-MiniLM-L6-v2_embeddings.npy\")\n",
    "metadata_path = os.path.join(embeddings_dir, \"all-MiniLM-L6-v2_metadata.json\")\n",
    "db_dir = os.path.join(current_dir.parent, \"models\", \"indexes\", \"chroma_db_new\")\n",
    "\n",
    "# Ruta al modelo descargado con LM Studio\n",
    "# IMPORTANTE: Debes cambiar esta ruta al archivo GGUF específico dentro de la carpeta del modelo\n",
    "model_path = r\"C:\\Users\\Usuario\\.lmstudio\\models\\lmstudio-community\\Mistral-7B-Instruct-v0.3-GGUF\\Mistral-7B-Instruct-v0.3-Q4_K_M.gguf\"\n",
    "\n",
    "# Verificar si el archivo del modelo existe\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"El archivo del modelo no existe en {model_path}\")\n",
    "    print(\"Por favor, verifica la ruta correcta al archivo .gguf del modelo\")\n",
    "    \n",
    "    # Solicitar la ruta al usuario\n",
    "    model_path = input(\"Introduce la ruta correcta al archivo .gguf del modelo: \")\n",
    "\n",
    "# Crear una base de datos completamente nueva\n",
    "print(\"Creando nueva base de datos vectorial a partir de los embeddings existentes...\")\n",
    "collection = create_fresh_db(embeddings_path, metadata_path, db_dir)\n",
    "\n",
    "# Iniciar interfaz de consola\n",
    "print(\"Iniciando interfaz de consola...\")\n",
    "\n",
    "# Ejecutar consulta de prueba\n",
    "test_query = \"¿Cuáles son las principales dependencias de Europa en materias primas críticas?\"\n",
    "print(f\"\\nConsulta de prueba: {test_query}\")\n",
    "\n",
    "answer, context, results = rag_query(test_query, collection, model_path=model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESPUESTA:\")\n",
    "print(answer)\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Iniciar interfaz interactiva\n",
    "interactive_rag(collection, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dependencias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
