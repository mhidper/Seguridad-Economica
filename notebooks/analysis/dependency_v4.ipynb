{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align=\"center\"><strong>C√°lculo de dependencia cruzada para todos los pa√≠ses</strong></h1>\n",
    "<h4 align=\"center\"><strong>Manuel Alejandro Hidalgo y Jorge D√≠az Lanchas</strong></h4>\n",
    "<h4 align=\"center\"><strong>Fundaci√≥n Real Instituto Elcano</strong></h4>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esquema para √çndice de Seguridad Econ√≥mica - Real Instituto Elcano\n",
    "\n",
    "## 1. Introducci√≥n y Marco Conceptual\n",
    "\n",
    "- **Objetivo**: Desarrollar un √≠ndice que cuantifique la seguridad econ√≥mica de los pa√≠ses\n",
    "- **Definici√≥n**: La seguridad econ√≥mica como la capacidad de un pa√≠s para resistir disrupciones en sus cadenas de suministro y comercio internacional\n",
    "- **Relevancia**: Contexto actual de fragmentaci√≥n geoecon√≥mica y tensiones comerciales\n",
    "\n",
    "## 2. Metodolog√≠a\n",
    "\n",
    "### 2.1 Fuentes de Datos\n",
    "- Base de datos International Trade and Production Database (ITP)\n",
    "- Datos comerciales bilaterales por industria (a√±o 2019)\n",
    "- Otros indicadores macroecon√≥micos complementarios\n",
    "\n",
    "### 2.2 Procesamiento de Datos\n",
    "```python\n",
    "# Procesamiento y carga de datos ITP\n",
    "itp2019, codigos_countries = procesar_datos_itp()\n",
    "```\n",
    "\n",
    "### 2.3 Creaci√≥n de Matrices de Comercio\n",
    "```python\n",
    "# Generaci√≥n de matrices bilaterales por industria\n",
    "matrices_comercio = crear_matriz_comercio(data.groupby('industry_descr'), codigos_paises)\n",
    "```\n",
    "\n",
    "### 2.4 Limpieza y Filtrado\n",
    "```python\n",
    "# Eliminar relaciones comerciales insignificantes\n",
    "mat_clean = eliminar_filas_columnas_cero(mat, threshold_pct=0.05)\n",
    "```\n",
    "\n",
    "### 2.5 C√°lculo de Dependencias Econ√≥micas\n",
    "```python\n",
    "# C√°lculo de dependencias directas e indirectas\n",
    "results = analyze_dependencies(X, country_names)\n",
    "```\n",
    "\n",
    "## 3. Componentes del √çndice\n",
    "\n",
    "### 3.1 Dependencia Directa\n",
    "- Medici√≥n de la dependencia inmediata entre pa√≠ses\n",
    "- F√≥rmula: $D_{ij} = \\frac{X_{ji}}{‚àë_k X_{ki}}$, donde $X_{ji}$ es el comercio del pa√≠s j al pa√≠s i\n",
    "\n",
    "### 3.2 Dependencia Indirecta\n",
    "- Medici√≥n de dependencias a trav√©s de cadenas de suministro\n",
    "- Incorporaci√≥n de pa√≠ses intermediarios en las relaciones comerciales\n",
    "- An√°lisis de caminos hasta longitud 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OPENBLAS_NUM_THREADS = 1\n",
      "‚úì MKL_NUM_THREADS = 1\n",
      "‚úì OMP_NUM_THREADS = 1\n",
      "‚úì NUMEXPR_NUM_THREADS = 1\n"
     ]
    }
   ],
   "source": [
    "# MEJOR - con validaci√≥n y logging\n",
    "import os as _os\n",
    "_threading_envs = {\n",
    "    \"OPENBLAS_NUM_THREADS\": \"1\",\n",
    "    \"MKL_NUM_THREADS\": \"1\", \n",
    "    \"OMP_NUM_THREADS\": \"1\",\n",
    "    \"NUMEXPR_NUM_THREADS\": \"1\"\n",
    "}\n",
    "for env_var, value in _threading_envs.items():\n",
    "    _os.environ.setdefault(env_var, value)\n",
    "    print(f\"‚úì {env_var} = {value}\")\n",
    "    \n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import torch\n",
    "\n",
    "# A√±adimos soporte esparso para futuros c√°lculos eficientes\n",
    "from scipy import sparse  # <- nuevo\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib\")\n",
    "\n",
    "\n",
    "# (Opcional) detecci√≥n segura de CuPy sin importarlo directamente (evita aviso del linter)\n",
    "import importlib.util as _importlib_util\n",
    "_cp_spec = _importlib_util.find_spec(\"cupy\")\n",
    "cp = None  # placeholder para evitar NameError si luego lo referenciamos\n",
    "if _cp_spec is not None:\n",
    "    # Solo importamos si realmente est√° instalado\n",
    "    import importlib as _importlib\n",
    "    cp = _importlib.import_module(\"cupy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***No ejecutar este c√≥digo a menos que se quiera comprimir***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprimir_dividir_archivo(archivo_original, tamano_maximo=100, directorio_salida=None):\n",
    "    # Aseg√∫rate de que el archivo original existe\n",
    "    archivo_original = Path(archivo_original)\n",
    "    if not archivo_original.exists():\n",
    "        raise FileNotFoundError(f\"No se encuentra el archivo: {archivo_original}\")\n",
    "    \n",
    "    # Si no se especifica directorio de salida, usar src/data/raw/ITP/\n",
    "    if directorio_salida is None:\n",
    "        # Obtener el directorio ra√≠z del proyecto (donde est√° src/)\n",
    "        proyecto_root = Path.cwd().parent.parent\n",
    "        directorio_salida = proyecto_root /'data' / 'raw' / 'ITP' / 'ITPD_E_R03'\n",
    "    else:\n",
    "        directorio_salida = Path(directorio_salida)\n",
    "    \n",
    "    # Crear el directorio de salida si no existe\n",
    "    directorio_salida.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Abre el archivo original en modo de lectura binaria\n",
    "    with open(archivo_original, 'rb') as f_in:\n",
    "        # Lee el contenido del archivo original\n",
    "        contenido = f_in.read()\n",
    "        \n",
    "        # Determina el n√∫mero de partes necesarias\n",
    "        num_partes = (len(contenido) + tamano_maximo - 1) // tamano_maximo\n",
    "        \n",
    "        # Divide el contenido en partes y escribe cada parte comprimida\n",
    "        for i in range(num_partes):\n",
    "            parte = contenido[i * tamano_maximo: (i + 1) * tamano_maximo]\n",
    "            archivo_salida = directorio_salida / f'ITPD_E_R03.csv.parte{i}.gz'\n",
    "            with gzip.open(archivo_salida, 'wb') as f_out:\n",
    "                f_out.write(parte)\n",
    "            print(f\"Parte {i} creada en: {archivo_salida}\")\n",
    "\n",
    "# Tama√±o m√°ximo por parte (1GB)\n",
    "tamano_maximo = 810 * 1024 * 1024\n",
    "\n",
    "try:\n",
    "    # Ruta al archivo original\n",
    "    archivo_original = Path(r\"C:\\Users\\Usuario\\Downloads\\ITPDE_R03\\ITPDE_R03.csv\")\n",
    "    \n",
    "    # Comprimir y dividir el archivo original\n",
    "    comprimir_dividir_archivo(archivo_original, tamano_maximo)\n",
    "    print(\"Proceso completado con √©xito\")\n",
    "except Exception as e:\n",
    "    print(f\"Error durante el proceso: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Descomprimir, carga de datos y borrado de archivo***\n",
    "\n",
    "La compresi√≥n se hace para poder trabajar con git sin porblemas de tama√±o de ficheros.\n",
    "Se descomprime, se importa y luego se borra el fichero descomprimido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINO EL A√ëO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anio = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Directorio fuente: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\raw\\ITP\\ITPD_E_R03\n",
      "Directorio destino: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\n",
      "Combinando archivos comprimidos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando archivos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:17<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo archivo CSV...\n",
      "Usando Dask para procesamiento en paralelo (lectura filtrada)\n",
      "Filtrando datos del a√±o 2022...\n",
      "Archivo temporal eliminado\n",
      "Total de pa√≠ses √∫nicos encontrados: 236\n",
      "Procesamiento completado con √©xito\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FASE 1: PREPARACI√ìN Y CARGA DE DATOS\n",
    "Este script procesa la base de datos International Trade and Production Database (ITP)\n",
    "que viene dividida en m√∫ltiples archivos comprimidos, utilizando aceleraci√≥n GPU\n",
    "cuando est√° disponible.\n",
    "\"\"\"\n",
    "\n",
    "def procesar_datos_itp(year: int = anio):\n",
    "    try:\n",
    "        # Verificar si GPU est√° disponible (solo informativo en esta fase)\n",
    "        gpu_disponible = torch.cuda.is_available()\n",
    "        if gpu_disponible:\n",
    "            print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"GPU no disponible, se usar√° CPU\")\n",
    "\n",
    "        # Definici√≥n de rutas usando Path y la estructura de tu proyecto\n",
    "        try:\n",
    "            base_path = Path(__file__).parent\n",
    "        except NameError:  # Estamos en un notebook\n",
    "            base_path = Path.cwd().parent.parent  # Asumiendo que el notebook est√° en /notebooks/\n",
    "\n",
    "        source_directory = base_path / \"data\" / \"raw\" / \"ITP\" / \"ITPD_E_R03\"\n",
    "        target_directory = base_path / \"data\" / \"processed\"\n",
    "        target_filename = 'ITPD_E_R03.csv'\n",
    "\n",
    "        # Imprimir las rutas para verificaci√≥n\n",
    "        print(f\"Directorio fuente: {source_directory}\")\n",
    "        print(f\"Directorio destino: {target_directory}\")\n",
    "\n",
    "        # Asegurar que los directorios existen\n",
    "        target_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Verificar que el directorio fuente existe\n",
    "        if not source_directory.exists():\n",
    "            raise FileNotFoundError(f\"No se encuentra el directorio fuente: {source_directory}\")\n",
    "\n",
    "        # Listar archivos comprimidos\n",
    "        chunk_filenames = sorted([\n",
    "            f for f in os.listdir(source_directory)\n",
    "            if f.startswith('ITPD_E_R03.csv.parte') and f.endswith('.gz')\n",
    "        ])\n",
    "\n",
    "        # Control de errores: verificar que existen archivos para procesar\n",
    "        if not chunk_filenames:\n",
    "            raise FileNotFoundError(f\"No se encontraron archivos .gz en {source_directory}\")\n",
    "\n",
    "        # Construir la ruta completa para el archivo combinado\n",
    "        target_filepath = target_directory / target_filename\n",
    "\n",
    "        # Funci√≥n para descomprimir un archivo en paralelo\n",
    "        def descomprimir_archivo(chunk_filename):\n",
    "            chunk_filepath = source_directory / chunk_filename\n",
    "            with gzip.open(chunk_filepath, 'rb') as chunk_file:\n",
    "                return chunk_file.read()\n",
    "\n",
    "        print(\"Combinando archivos comprimidos...\")\n",
    "        with open(target_filepath, 'wb') as target_file:\n",
    "            # Usar ThreadPoolExecutor para paralelizar la descompresi√≥n (I/O + gzip)\n",
    "            with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "                for data in tqdm(\n",
    "                    executor.map(descomprimir_archivo, chunk_filenames),\n",
    "                    total=len(chunk_filenames),\n",
    "                    desc=\"Procesando archivos\"\n",
    "                ):\n",
    "                    target_file.write(data)\n",
    "\n",
    "                print(\"Leyendo archivo CSV...\")\n",
    "\n",
    "                # === columnas exactas que necesitas ===\n",
    "                USECOLS = [\n",
    "                    \"exporter_iso3\",\n",
    "                    \"importer_iso3\",\n",
    "                    \"year\",\n",
    "                    \"trade\",\n",
    "                    \"industry_id\",\n",
    "                    \"industry_descr\",\n",
    "                    \"importer_name\",\n",
    "                    \"exporter_name\",\n",
    "                ]\n",
    "                DTYPES = {\n",
    "                    \"exporter_iso3\": \"string\",\n",
    "                    \"importer_iso3\": \"string\",\n",
    "                    \"year\": \"int32\",\n",
    "                    \"trade\": \"float32\",        # reduce memoria sin perder precisi√≥n pr√°ctica\n",
    "                    \"industry_id\": \"int32\",\n",
    "                    \"industry_descr\": \"string\",\n",
    "                    \"importer_name\": \"string\",\n",
    "                    \"exporter_name\": \"string\",\n",
    "                }\n",
    "\n",
    "                # Dask: lectura lazy del CSV combinado\n",
    "                print(\"Usando Dask para procesamiento en paralelo (lectura filtrada)\")\n",
    "                dask_df = dd.read_csv(\n",
    "                    target_filepath,\n",
    "                    sep=\",\",\n",
    "                    usecols=USECOLS,\n",
    "                    dtype=DTYPES,\n",
    "                    blocksize=\"128MB\",\n",
    "                    assume_missing=True,  # tolerante a nulos espor√°dicos\n",
    "                )\n",
    "                dask_df['year'].unique()\n",
    "                print(f\"Filtrando datos del a√±o {year}...\")\n",
    "                dask_df = dask_df[dask_df[\"year\"] == year]\n",
    "\n",
    "                # Ejecutar el plan y materializar en pandas\n",
    "                itp_year = dask_df.compute()\n",
    "\n",
    "                # Tipos finales (por si Dask promovi√≥ algo)\n",
    "                itp_year = itp_year.astype(DTYPES)\n",
    "\n",
    "                # (Opcional) comprime memoria de las cadenas con 'category' si vas a agrupar mucho despu√©s\n",
    "                # itp_year[\"exporter_iso3\"]  = itp_year[\"exporter_iso3\"].astype(\"category\")\n",
    "                # itp_year[\"importer_iso3\"]  = itp_year[\"importer_iso3\"].astype(\"category\")\n",
    "                # itp_year[\"industry_descr\"] = itp_year[\"industry_descr\"].astype(\"category\")\n",
    "                # itp_year[\"importer_name\"]  = itp_year[\"importer_name\"].astype(\"category\")\n",
    "                # itp_year[\"exporter_name\"]  = itp_year[\"exporter_name\"].astype(\"category\")\n",
    "\n",
    "\n",
    "        # Limpieza del temporal grande\n",
    "        try:\n",
    "            os.remove(target_filepath)\n",
    "            print(\"Archivo temporal eliminado\")\n",
    "        except Exception as _e:\n",
    "            print(f\"Advertencia: no se pudo eliminar el temporal ({_e})\")\n",
    "\n",
    "        # 4) Pa√≠ses √∫nicos importadores (GPU no aporta aqu√≠; unique de pandas es muy r√°pido)\n",
    "        #    Convertimos a category para memoria/velocidad y extraemos categor√≠as ordenadas\n",
    "        itp_year[\"importer_iso3\"] = itp_year[\"importer_iso3\"].astype(\"category\")\n",
    "        codigos_countries = list(itp_year[\"importer_iso3\"].cat.categories)\n",
    "\n",
    "        print(f\"Total de pa√≠ses √∫nicos encontrados: {len(codigos_countries)}\")\n",
    "        return itp_year, codigos_countries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el procesamiento: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data, countries = procesar_datos_itp(year=anio)\n",
    "        print(\"Procesamiento completado con √©xito\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la ejecuci√≥n principal: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cat√°logo de industrias generado: 170 filas\n",
      "- CSV: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\Dependencias_consolidadas\\industrias_id_nombre.csv\n",
      "- Parquet: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\Dependencias_consolidadas\\industrias_id_nombre.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Posibles alias de columnas en ITP (ajusta si conoces los exactos)\n",
    "CAND_ID = [\"industry_id\", \"industry_code\", \"industry\", \"sector_id\", \"sector_code\", \"isic\", \"isic4\"]\n",
    "CAND_NAME = [\"industry_descr\", \"industry_name\", \"industry_label\", \"sector_name\", \"sector_descr\"]\n",
    "\n",
    "def _pick_col(candidates, cols):\n",
    "    cols_lower = {c.lower(): c for c in cols}\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in cols_lower:\n",
    "            return cols_lower[cand.lower()]\n",
    "    return None\n",
    "\n",
    "id_col = _pick_col(CAND_ID, data.columns)\n",
    "name_col = _pick_col(CAND_NAME, data.columns)\n",
    "\n",
    "if not id_col or not name_col:\n",
    "    print(\"‚ö†Ô∏è No se encontraron columnas de industria en 'data'.\")\n",
    "    print(f\"Columnas disponibles: {list(data.columns)}\")\n",
    "    print(\n",
    "        \"Sugerencia: en la celda de carga (procesar_datos_itp), a√±ade las columnas de industria \"\n",
    "        \"a USECOLS/DTYPES, por ejemplo: 'industry_id' y 'industry_descr' (o sus equivalentes).\"\n",
    "    )\n",
    "else:\n",
    "    # Cat√°logo √∫nico, limpio y ordenado\n",
    "    industrias = (\n",
    "        data[[id_col, name_col]]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .sort_values([id_col, name_col])\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns={id_col: \"industry_id\", name_col: \"industry_descr\"})\n",
    "    )\n",
    "\n",
    "    # Tipos compactos\n",
    "    industrias[\"industry_id\"] = industrias[\"industry_id\"].astype(\"string\")\n",
    "    industrias[\"industry_descr\"] = industrias[\"industry_descr\"].astype(\"string\")\n",
    "\n",
    "    # Rutas (evitamos espacios en nombres de carpetas)\n",
    "    base_path = Path.cwd().parent.parent\n",
    "    target_directory = base_path / \"data\" / \"processed\" / \"Dependencias_consolidadas\"\n",
    "    target_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salidas\n",
    "    csv_path = target_directory / \"industrias_id_nombre.csv\"\n",
    "    pq_path  = target_directory / \"industrias_id_nombre.parquet\"\n",
    "\n",
    "    industrias.to_csv(csv_path, sep=\";\", index=False)\n",
    "    industrias.to_parquet(pq_path, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Cat√°logo de industrias generado: {len(industrias)} filas\")\n",
    "    print(f\"- CSV: {csv_path}\")\n",
    "    print(f\"- Parquet: {pq_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Creaci√≥n de Matrices de Comercio Bilateral Optimizada\n",
    "\n",
    "Esta funci√≥n transforma los datos comerciales brutos en un conjunto de **matrices cuadradas alineadas**, \n",
    "una por cada industria.\n",
    "\n",
    "#### üéØ Qu√© hace\n",
    "\n",
    "1. **Valida** que las entradas sean correctas (GroupBy object, pa√≠ses v√°lidos)\n",
    "2. **Extrae columnas** de exportador, importador y valor de comercio\n",
    "3. **Para cada industria:**\n",
    "   - Filtra a solo pa√≠ses en nuestra lista de an√°lisis\n",
    "   - Crea matriz bilateral: filas=exportadores, columnas=importadores\n",
    "   - Asegura que todas las matrices sean cuadradas (236√ó236) y alineadas\n",
    "4. **Calcula y guarda** totales de importaci√≥n por pa√≠s-industria (para auditor√≠a)\n",
    "\n",
    "#### üìê Estructura de output\n",
    "```python\n",
    "matrices_comercio = {\n",
    "    \"Machinery\": DataFrame(236√ó236),\n",
    "    \"Chemicals\": DataFrame(236√ó236),\n",
    "    \"Electronics\": DataFrame(236√ó236),\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Donde cada matriz cumple:\n",
    "- **√çndice** = c√≥digos ISO3 de exportadores\n",
    "- **Columnas** = c√≥digos ISO3 de importadores  \n",
    "- **Valor [i,j]** = flujo comercial del pa√≠s i al pa√≠s j en esa industria\n",
    "- **Todos los ceros garantizados** = pares no observados = comercio nulo\n",
    "\n",
    "#### üîß Mejoras en esta versi√≥n\n",
    "\n",
    "- ‚úÖ Validaci√≥n robusta de entrada\n",
    "- ‚úÖ Mensajes de error claros y accionables\n",
    "- ‚úÖ Resoluci√≥n autom√°tica de directorios\n",
    "- ‚úÖ Logging opcional para debugging\n",
    "- ‚úÖ Comentarios en el c√≥digo explicando cada paso\n",
    "- ‚úÖ CSV de referencia para auditor√≠a post-c√°lculo\n",
    "\n",
    "#### ‚ö†Ô∏è Notas importantes\n",
    "\n",
    "- Las matrices se guardan en memoria como **float32** para eficiencia (suficiente para valores de comercio)\n",
    "- Los totales se guardan como referencia, pero se **recalculan** en la siguiente etapa de an√°lisis\n",
    "- Las matrices resultantes son la **base para todos los c√°lculos de dependencia posteriores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_matriz_comercio_optimizado(\n",
    "    grouped_data, \n",
    "    codigos_paises: List[str],\n",
    "    target_directory: Path | None = None,\n",
    "    verbose: bool = False\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Crea matrices de comercio bilateral (exportador √ó importador) para cada industria.\n",
    "    \n",
    "    Esta funci√≥n transforma datos comerciales desagregados en matrices cuadradas alineadas,\n",
    "    donde cada elemento [i,j] representa el flujo comercial del pa√≠s i al pa√≠s j.\n",
    "    \n",
    "    Args:\n",
    "        grouped_data: Resultado de df.groupby('industry_descr'). Debe ser un GroupBy object.\n",
    "        codigos_paises: Lista de c√≥digos ISO3 a usar como √≠ndices de las matrices.\n",
    "        target_directory: Carpeta donde guardar CSV de totales. Si None, usa path relativa al proyecto.\n",
    "        verbose: Si True, imprime mensajes de progreso y validaci√≥n.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {nombre_industria -> DataFrame(index=exportadores, columns=importadores)}\n",
    "        \n",
    "    Side effect:\n",
    "        Guarda CSV comprimido con totales de importaci√≥n por pa√≠s-industria para referencia.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ==================== VALIDACIONES ====================\n",
    "    \n",
    "    # Validar que grouped_data sea un GroupBy object\n",
    "    if not hasattr(grouped_data, '__iter__') or not hasattr(grouped_data, 'obj'):\n",
    "        raise TypeError(\n",
    "            \"‚ùå grouped_data debe ser resultado de df.groupby()\\n\"\n",
    "            \"   Ejemplo: data.groupby('industry_descr')\"\n",
    "        )\n",
    "    \n",
    "    # Validar que codigos_paises no est√© vac√≠o\n",
    "    if not codigos_paises or len(codigos_paises) < 2:\n",
    "        raise ValueError(\n",
    "            f\"‚ùå codigos_paises debe tener al menos 2 pa√≠ses. Recibido: {len(codigos_paises)}\"\n",
    "        )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"‚úì Entrada validada: {len(codigos_paises)} pa√≠ses\")\n",
    "    \n",
    "    # ==================== RESOLUCI√ìN DE DIRECTORIOS ====================\n",
    "    \n",
    "    if target_directory is None:\n",
    "        try:\n",
    "            # Si se ejecuta como script\n",
    "            base_path = Path(__file__).parent\n",
    "        except NameError:\n",
    "            # Si se ejecuta en notebook\n",
    "            base_path = Path.cwd().parent.parent\n",
    "        \n",
    "        target_directory = base_path / \"data\" / \"processed\" / \"totales_comercio_por_pais_ind\"\n",
    "    \n",
    "    target_directory = Path(target_directory)\n",
    "    target_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"‚úì Directorio de salida: {target_directory}\")\n",
    "    \n",
    "    # ==================== B√öSQUEDA DE COLUMNAS REQUERIDAS ====================\n",
    "    \n",
    "    cols = grouped_data.obj.columns\n",
    "    \n",
    "    # Validar que existan columnas de exportador/importador\n",
    "    required = {\"exporter_iso3\", \"importer_iso3\"}\n",
    "    missing = required - set(cols)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"‚ùå Faltan columnas requeridas: {missing}\\n\"\n",
    "            f\"   Disponibles: {list(cols)}\"\n",
    "        )\n",
    "    \n",
    "    # Buscar columna de valores de comercio (con prioridad)\n",
    "    trade_col = None\n",
    "    for cand in (\"trade\", \"value\", \"trade_value\"):\n",
    "        if cand in cols:\n",
    "            trade_col = cand\n",
    "            break\n",
    "    \n",
    "    if trade_col is None:\n",
    "        # Sugerir alternativas si las hay\n",
    "        available_value_cols = [c for c in cols if 'trade' in c.lower() or 'value' in c.lower()]\n",
    "        raise ValueError(\n",
    "            f\"‚ùå No encontr√© columna de valores de comercio (buscaba: 'trade', 'value', 'trade_value')\\n\"\n",
    "            f\"   Candidatos similares: {available_value_cols}\\n\"\n",
    "            f\"   Todas las columnas: {list(cols)}\"\n",
    "        )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"‚úì Columna de comercio detectada: '{trade_col}'\")\n",
    "    \n",
    "    # ==================== INICIALIZACI√ìN ====================\n",
    "    \n",
    "    matrices: Dict[str, pd.DataFrame] = {}\n",
    "    totales_registros = []\n",
    "    \n",
    "    # Pre-calcular template: matriz vac√≠a con √≠ndices alineados\n",
    "    # Todos los pa√≠ses en todas las combinaciones, rellenados con ceros\n",
    "    template = pd.DataFrame(\n",
    "        0.0, \n",
    "        index=codigos_paises, \n",
    "        columns=codigos_paises, \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    # ==================== PROCESAMIENTO POR INDUSTRIA ====================\n",
    "    \n",
    "    for industry, group in grouped_data:\n",
    "        # PASO 1: Filtrar a solo los pa√≠ses en nuestra lista\n",
    "        # Esto evita que haya pa√≠ses fuera de scope en las matrices\n",
    "        g = group[\n",
    "            group[\"exporter_iso3\"].isin(codigos_paises) &\n",
    "            group[\"importer_iso3\"].isin(codigos_paises)\n",
    "        ]\n",
    "        \n",
    "        # CASO: Industria sin datos v√°lidos\n",
    "        if g.empty:\n",
    "            # Guardar matriz vac√≠a (todos ceros) para consistencia\n",
    "            matrices[industry] = template.copy()\n",
    "            \n",
    "            # Registrar totales como cero para todos los pa√≠ses en esta industria\n",
    "            totales_registros.extend(\n",
    "                {\n",
    "                    \"pais\": p, \n",
    "                    \"industria\": industry, \n",
    "                    \"valor_importado\": 0.0\n",
    "                }\n",
    "                for p in codigos_paises\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        # CASO: Industria con datos\n",
    "        # PASO 2: Crear matriz bilateral mediante pivot\n",
    "        # - index: exportadores (origen)\n",
    "        # - columns: importadores (destino)\n",
    "        # - values: suma de comercio (en caso de m√∫ltiples registros por par)\n",
    "        mat = (\n",
    "            g.pivot_table(\n",
    "                index=\"exporter_iso3\",\n",
    "                columns=\"importer_iso3\",\n",
    "                values=trade_col,\n",
    "                aggfunc=\"sum\",              # Si hay duplicados, sumarlos\n",
    "                fill_value=0.0,             # Pares no observados ‚Üí 0\n",
    "                observed=False              # Incluir todas las combinaciones\n",
    "            )\n",
    "            # PASO 3: Alinear a matriz cuadrada completa\n",
    "            # Asegura que todos los pa√≠ses est√©n presentes, aunque no tengan comercio\n",
    "            .reindex(index=codigos_paises, columns=codigos_paises, fill_value=0.0)\n",
    "            .astype(np.float32)             # Reducir memoria: float32 suficiente\n",
    "        )\n",
    "        \n",
    "        matrices[industry] = mat\n",
    "        \n",
    "        # PASO 4: Calcular totales de importaci√≥n por pa√≠s en esta industria\n",
    "        # .sum(axis=0) suma por columna = suma de todos los exportadores hacia cada importador\n",
    "        totales = mat.sum(axis=0)\n",
    "        totales_registros.extend(\n",
    "            {\n",
    "                \"pais\": pais, \n",
    "                \"industria\": industry, \n",
    "                \"valor_importado\": float(totales[pais])\n",
    "            }\n",
    "            for pais in codigos_paises\n",
    "        )\n",
    "    \n",
    "    # ==================== GUARDADO DE REFERENCIA ====================\n",
    "    \n",
    "    # Convertir a DataFrame y guardar como referencia\n",
    "    # (se recalcula en calculate_all_dependencies, pero √∫til para validaci√≥n/auditor√≠a)\n",
    "    df_totales = pd.DataFrame(totales_registros)\n",
    "    df_path = target_directory / f\"totales_comercio_por_pais_industria{anio}.csv\"\n",
    "    df_totales.to_csv(df_path, index=False, sep=\";\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"‚úì Totales guardados en: {df_path}\")\n",
    "        print(f\"‚úì Matrices creadas: {len(matrices)} industrias\")\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "\n",
    "\n",
    "# Define la lista de c√≥digos de pa√≠ses\n",
    "codigos_paises = sorted(data['importer_iso3'].unique().tolist())\n",
    "\n",
    "# Llama a la funci√≥n optimizada (mismo API esperado)\n",
    "matrices_comercio = crear_matriz_comercio_optimizado(\n",
    "    data.groupby('industry_descr'),\n",
    "    codigos_paises=codigos_paises,\n",
    "    # target_directory=Path(\"...\")  # opcional\n",
    ")\n",
    "\n",
    "def eliminar_filas_columnas_cero(df: pd.DataFrame, threshold_pct: float = 0.005) -> pd.DataFrame:\n",
    "    \"\"\"Filtra una matriz aplicando umbral relativo por pa√≠s importador (columna).\"\"\"\n",
    "    # Umbral por columna: total_col * pct\n",
    "    col_totals = df.sum(axis=0)\n",
    "    thresholds = col_totals * float(threshold_pct)\n",
    "\n",
    "    # Aplicar m√°scara vectorizada (alineaci√≥n por columnas)\n",
    "    df_filtered = df.where(df >= thresholds, 0.0)\n",
    "\n",
    "    # Pa√≠ses con filas y columnas a cero tras umbral\n",
    "    zero_rows = df_filtered.index[df_filtered.sum(axis=1) == 0.0]\n",
    "    zero_cols = df_filtered.columns[df_filtered.sum(axis=0) == 0.0]\n",
    "    to_drop = list(set(zero_rows) & set(zero_cols))\n",
    "\n",
    "    return df_filtered.drop(index=to_drop, columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîó C√°lculo de Dependencias Comerciales: Directas e Indirectas\n",
    "\n",
    "Esta celda implementa el **n√∫cleo de la metodolog√≠a PIVI**: calcula c√≥mo cada pa√≠s depende de otros para cada par bilateral (importador ‚Üí exportador), considerando no solo el comercio directo sino tambi√©n las **cadenas de intermediarios** que canalizan el flujo comercial.\n",
    "\n",
    "#### üéØ Qu√© hace\n",
    "\n",
    "Transforma una matriz de comercio bilateral en un conjunto completo de **m√©tricas de dependencia**:\n",
    "- **Dependencia directa (L=1):** flujo directo importador ‚Üê exportador\n",
    "- **Dependencia indirecta (L‚â•2):** flujo canalizado a trav√©s de intermediarios\n",
    "- **Caminos significativos:** rutas concretas que contribuyen a la dependencia\n",
    "- **Intermediarios cr√≠ticos:** pa√≠ses que act√∫an como \"hubs\" en el comercio\n",
    "\n",
    "#### üèóÔ∏è Estructura de funciones\n",
    "\n",
    "**process_country_pair()** - Calcula dependencia para UN par (importador i, exportador j):\n",
    "- Dependencia directa: X[j,i] / importaciones_totales[i]\n",
    "- Crea matriz de transici√≥n T: normaliza flujos por importador\n",
    "- L=2 (vectorizado): suma de todos los intermediarios con una operaci√≥n matricial\n",
    "- L‚â•3 (combinations): enumeraci√≥n de caminos m√°s largos con poda por threshold\n",
    "- Retorna: dependencias_por_longitud + caminos_significativos\n",
    "\n",
    "**calculate_all_dependencies_parallel()** - Paraleliza process_country_pair() para TODOS los pares:\n",
    "- GPU (opcional): prepara aceleraci√≥n si est√° disponible\n",
    "- Joblib: distribuye c√°lculo en m√∫ltiples n√∫cleos\n",
    "- Agrega resultados por importador\n",
    "- Calcula centralidad de intermediarios\n",
    "- Retorna: estructura consolidada de resultados\n",
    "\n",
    "**calculate_all_dependencies()** - Wrapper que decide si usar paralelizaci√≥n:\n",
    "- Valida tama√±o del problema\n",
    "- Llama a calculate_all_dependencies_parallel() con par√°metros √≥ptimos\n",
    "\n",
    "#### üìä Output principal\n",
    "```python\n",
    "results = {\n",
    "    'dependencies': [  # Lista de dicts con cada relaci√≥n bilateral\n",
    "        {\n",
    "            'importador': 'ESP',\n",
    "            'exportador': 'CHN',\n",
    "            'dependencia_total': 0.794,\n",
    "            'dependencia_directa': 0.598,\n",
    "            'dependencia_indirecta': 0.196,\n",
    "            'longitud_optima': 3,\n",
    "            'dependencias_por_longitud': {1: 0.598, 2: 0.162, 3: 0.034},\n",
    "            'trade_value': 1912.42\n",
    "        },\n",
    "        ...  # uno por cada par i‚â†j (236¬≤ - 236 = 54,756 pares)\n",
    "    ],\n",
    "    \n",
    "    'top_dependencies': [  # Top 90 pares m√°s dependientes\n",
    "        (importador, exportador, DD, DI, DT, longitud), ...\n",
    "    ],\n",
    "    \n",
    "    'critical_paths': [  # Rutas espec√≠ficas con fuerza > threshold\n",
    "        {\n",
    "            'exportador': 'CHN',\n",
    "            'importador': 'ESP',\n",
    "            'intermediarios': ['DEU', 'HUN'],\n",
    "            'fuerza': 0.0039,\n",
    "            'longitud': 3\n",
    "        }, ...\n",
    "    ],\n",
    "    \n",
    "    'intermediary_centrality': [  # Pa√≠ses rankeados como intermediarios\n",
    "        ('DEU', freq=145, strength=23.4, score=0.87),\n",
    "        ('CHN', freq=132, strength=18.2, score=0.81),\n",
    "        ...\n",
    "    ],\n",
    "    \n",
    "    'critical_intermediaries': {  # Rutas por cada par bilateral\n",
    "        'CHN->ESP': [path_dict, path_dict, ...],\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### ‚öôÔ∏è Par√°metros clave\n",
    "\n",
    "| Par√°metro | Default | Significado |\n",
    "|-----------|---------|-------------|\n",
    "| `max_possible_length` | 3 | Longitud m√°xima de cadenas a considerar (L_max) |\n",
    "| `convergence_threshold` | 0.01 | Umbral para detener si incremento < 1% |\n",
    "| `path_strength_threshold` | 0.001 | Fuerza m√≠nima de un camino para registrarlo |\n",
    "| `n_jobs` | CPU_count | N√∫mero de cores para paralelizaci√≥n |\n",
    "| `use_gpu` | True | Intenta usar GPU si disponible |\n",
    "\n",
    "#### üî¢ Complejidad computacional\n",
    "\n",
    "- **Pares evaluados:** n(n-1) donde n=236 pa√≠ses ‚Üí ~55k pares\n",
    "- **Caminos L=2:** O(n) combinaciones por par (r√°pido, vectorizado)\n",
    "- **Caminos L‚â•3:** O(C(n,L-1)) combinaciones ‚Üí exponencial pero poda por `path_strength_threshold`\n",
    "- **Tiempo t√≠pico:** ~10-30 min para 170 industrias en CPU con paralelizaci√≥n\n",
    "\n",
    "#### üìà Matriz de Transici√≥n T\n",
    "\n",
    "Punto crucial del algoritmo:\n",
    "```\n",
    "T[exportador, importador] = Comercio(exp‚Üíimp) / Importaciones_totales(imp)\n",
    "```\n",
    "\n",
    "**Interpretaci√≥n:** $$T[j,i]$$ representa la \"probabilidad\" de que una unidad importada por pa√≠s i provenga del pa√≠s j, considerando la composici√≥n actual del mercado de i. Esto permite calcular cadenas: si j abastece a k y k abastece a i, entonces la cadena es $$T[j,k] √ó T[k,i]$$.\n",
    "\n",
    "#### üßÆ F√≥rmulas de dependencia\n",
    "\n",
    "**Dependencia Directa (L=1):**\n",
    "$$DD_{i \\leftarrow j} = \\frac{X_{j \\to i}}{\\sum_k X_{k \\to i}}$$\n",
    "\n",
    "**Dependencia Indirecta (L=2):**\n",
    "$$DI^{(2)}_{i \\leftarrow j} = \\sum_k T_{j,k} \\cdot T_{k,i}$$ \n",
    "\n",
    "donde \n",
    "$$k ‚â† i, j$$\n",
    "\n",
    "**Dependencia Indirecta (L=3+):**\n",
    "$$DI^{(L)}_{i \\leftarrow j} = \\sum_{\\text{caminos}} T_{j,c_1} \\cdot T_{c_1,c_2} \\cdot \\ldots \\cdot T_{c_{L-2},i}$$\n",
    "\n",
    "**Dependencia Total:**\n",
    "$$DT_{i \\leftarrow j} = DD_{i \\leftarrow j} + \\sum_{L=2}^{L_{max}} DI^{(L)}_{i \\leftarrow j}$$\n",
    "\n",
    "#### üéØ Intermediarios cr√≠ticos\n",
    "\n",
    "Para cada pa√≠s, se calcula:\n",
    "- **Frecuencia:** cu√°ntas cadenas lo incluyen\n",
    "- **Fuerza:** suma ponderada de las fuerzas de esas cadenas\n",
    "- **Score de centralidad:** 0.4 √ó freq_normalizada + 0.6 √ó fuerza_normalizada\n",
    "\n",
    "Un pa√≠s con alta centralidad es un \"cuello de botella\" clave en el comercio global.\n",
    "\n",
    "#### ‚ö†Ô∏è Notas importantes\n",
    "\n",
    "- El algoritmo es **exhaustivo pero poda intelligentemente**: solo explora caminos con fuerza > `path_strength_threshold`\n",
    "- La convergencia t√≠picamente se alcanza en L=2 o L=3, rara vez necesita L=4+\n",
    "- Los resultados son **determin√≠sticos** y **reproducibles**\n",
    "- Est√° paralelizado para m√°ximo rendimiento, pero puede ejecutarse secuencial si se necesita debugging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_path_dependency(X_clean, path, denominators):\n",
    "    \"\"\"Calcula la dependencia de un camino espec√≠fico.\"\"\"\n",
    "    fuerza_camino = 1.0\n",
    "    for k in range(len(path) - 1):\n",
    "        if denominators[path[k+1]] > 0:\n",
    "            fuerza_camino *= X_clean[path[k], path[k+1]] / denominators[path[k+1]]\n",
    "        else:\n",
    "            fuerza_camino = 0  # Si el denominador es cero, la fuerza del camino es cero\n",
    "    return fuerza_camino\n",
    "\n",
    "def calculate_intermediary_centrality(intermediary_frequency, intermediary_strength, country_names):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas de centralidad para intermediarios.\n",
    "    \n",
    "    Esta funci√≥n es la misma que la original.\n",
    "    \"\"\"\n",
    "    # Implementaci√≥n existente\n",
    "    centrality = []\n",
    "    \n",
    "    # Normalizar\n",
    "    max_freq = max(intermediary_frequency.values()) if intermediary_frequency.values() else 1\n",
    "    max_strength = max(intermediary_strength.values()) if intermediary_strength.values() else 1\n",
    "    \n",
    "    for country in country_names:\n",
    "        norm_freq = intermediary_frequency[country] / max_freq if max_freq > 0 else 0\n",
    "        norm_strength = intermediary_strength[country] / max_strength if max_strength > 0 else 0\n",
    "        \n",
    "        combined_score = 0.4 * norm_freq + 0.6 * norm_strength\n",
    "        \n",
    "        centrality.append((country, intermediary_frequency[country], \n",
    "                          intermediary_strength[country], combined_score))\n",
    "    \n",
    "    centrality.sort(key=lambda x: x[3], reverse=True)\n",
    "    return centrality\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def process_country_pair(i, j, X_clean, denominators, country_names,\n",
    "                         max_possible_length, convergence_threshold,\n",
    "                         path_strength_threshold, T):\n",
    "    \"\"\"\n",
    "    Exactamente la misma definici√≥n que antes (combinations), pero:\n",
    "    - Usa T (matriz de transici√≥n) precalculada.\n",
    "    - Vectoriza la longitud 2.\n",
    "    - Mantiene mismos retornos y campos.\n",
    "    \"\"\"\n",
    "    n = X_clean.shape[0]\n",
    "\n",
    "    # Dependencia directa (igual que antes)\n",
    "    trade_value = X_clean[j, i]\n",
    "    direct_dependency = (X_clean[j, i] / denominators[i]) if denominators[i] > 0 else 0.0\n",
    "\n",
    "    dependencies_by_length = {1: direct_dependency}\n",
    "    significant_paths = []\n",
    "    current_total = direct_dependency\n",
    "    indirect_total = 0.0\n",
    "    length = 1\n",
    "\n",
    "    # Candidatos de intermediarios (igual que antes)\n",
    "    middle = [k for k in range(n) if k != i and k != j]\n",
    "\n",
    "    # ---- L = 2 (vectorizado, EXACTO) ----\n",
    "    if max_possible_length >= 2 and middle:\n",
    "        row_j = T[j, :]\n",
    "        col_i = T[:, i]\n",
    "        mask = np.ones(n, dtype=bool)\n",
    "        mask[[i, j]] = False\n",
    "\n",
    "        # suma exacta: sum_k T[j,k]*T[k,i], k!=i,j\n",
    "        di2 = np.dot(row_j[mask], col_i[mask])\n",
    "        dependencies_by_length[2] = float(di2)\n",
    "        indirect_total += float(di2)\n",
    "        current_total = direct_dependency + indirect_total\n",
    "        length = 2\n",
    "\n",
    "        # caminos significativos para L=2 (mismo umbral)\n",
    "        if path_strength_threshold > 0:\n",
    "            ks = np.nonzero(row_j * col_i > path_strength_threshold)[0]\n",
    "            ks = [k for k in ks if k != i and k != j]\n",
    "            if ks:\n",
    "                for k in ks:\n",
    "                    significant_paths.append({\n",
    "                        'exportador': country_names[j],\n",
    "                        'importador': country_names[i],\n",
    "                        'intermediarios': [country_names[k]],\n",
    "                        'fuerza': float(row_j[k] * col_i[k]),\n",
    "                        'longitud': 2\n",
    "                    })\n",
    "\n",
    "        # criterio de convergencia\n",
    "        if abs(current_total - direct_dependency) < convergence_threshold or max_possible_length == 2:\n",
    "            # ordenar y devolver\n",
    "            significant_paths.sort(key=lambda x: x['fuerza'], reverse=True)\n",
    "            pair_key = f\"{country_names[j]}->{country_names[i]}\"\n",
    "            result = {\n",
    "                'importador': country_names[i],\n",
    "                'exportador': country_names[j],\n",
    "                'trade_value': trade_value,\n",
    "                'dependencia_directa': direct_dependency,\n",
    "                'dependencia_indirecta': indirect_total,\n",
    "                'dependencia_total': direct_dependency + indirect_total,\n",
    "                'longitud_optima': 2,\n",
    "                'dependencias_por_longitud': dependencies_by_length\n",
    "            }\n",
    "            return {\n",
    "                'pair_key': pair_key,\n",
    "                'result': result,\n",
    "                'top_dependency': (country_names[i], country_names[j],\n",
    "                                   direct_dependency, indirect_total,\n",
    "                                   direct_dependency + indirect_total, 2),\n",
    "                'significant_paths': significant_paths,\n",
    "                'length_converged': 2\n",
    "            }\n",
    "\n",
    "    # ---- L >= 3 (exacto con combinations, pero usando T) ----\n",
    "    for L in range(3, max_possible_length + 1):\n",
    "        DI_ij_L = 0.0\n",
    "        for interms in combinations(middle, L - 1):\n",
    "            path = (j,) + interms + (i,)\n",
    "            # producto exacto de T a lo largo del camino\n",
    "            prod = 1.0\n",
    "            for a, b in zip(path[:-1], path[1:]):\n",
    "                w = T[a, b]\n",
    "                if w == 0.0:\n",
    "                    prod = 0.0\n",
    "                    break\n",
    "                prod *= w\n",
    "\n",
    "            DI_ij_L += prod\n",
    "\n",
    "            if prod > path_strength_threshold:\n",
    "                significant_paths.append({\n",
    "                    'exportador': country_names[j],\n",
    "                    'importador': country_names[i],\n",
    "                    'intermediarios': [country_names[x] for x in interms],\n",
    "                    'fuerza': float(prod),\n",
    "                    'longitud': L\n",
    "                })\n",
    "\n",
    "        dependencies_by_length[L] = float(DI_ij_L)\n",
    "        indirect_total += float(DI_ij_L)\n",
    "\n",
    "        prev_total = current_total\n",
    "        current_total = direct_dependency + indirect_total\n",
    "        length = L\n",
    "\n",
    "        if L > 1 and abs(current_total - prev_total) < convergence_threshold:\n",
    "            break\n",
    "\n",
    "    # Final\n",
    "    significant_paths.sort(key=lambda x: x['fuerza'], reverse=True)\n",
    "    total_dependency = direct_dependency + indirect_total\n",
    "    pair_key = f\"{country_names[j]}->{country_names[i]}\"\n",
    "    result = {\n",
    "        'importador': country_names[i],\n",
    "        'exportador': country_names[j],\n",
    "        'trade_value': trade_value,\n",
    "        'dependencia_directa': direct_dependency,\n",
    "        'dependencia_indirecta': indirect_total,\n",
    "        'dependencia_total': total_dependency,\n",
    "        'longitud_optima': length,\n",
    "        'dependencias_por_longitud': dependencies_by_length\n",
    "    }\n",
    "    return {\n",
    "        'pair_key': pair_key,\n",
    "        'result': result,\n",
    "        'top_dependency': (country_names[i], country_names[j],\n",
    "                           direct_dependency, indirect_total, total_dependency, length),\n",
    "        'significant_paths': significant_paths,\n",
    "        'length_converged': length if length > 1 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_all_dependencies_parallel(X, country_names=None, convergence_threshold=0.01, \n",
    "                                       max_possible_length=3, \n",
    "                                       path_strength_threshold=0.001, n_jobs=None, use_gpu=True, \n",
    "                                       debug_mode=False):\n",
    "    \"\"\"\n",
    "    Versi√≥n paralelizada del c√°lculo de dependencias que mantiene EXACTAMENTE\n",
    "    la misma salida que la versi√≥n original.\n",
    "    \n",
    "    El par√°metro debug_mode permite verificar que el n√∫mero de dependencias\n",
    "    coincida con la versi√≥n original.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Versi√≥n paralelizada del c√°lculo de dependencias.\n",
    "    \n",
    "    Parameters adicionales:\n",
    "    -----------------------\n",
    "    n_jobs : int, opcional\n",
    "        N√∫mero de trabajos paralelos. Si es None, usa todos los n√∫cleos disponibles.\n",
    "    use_gpu : bool, default=True\n",
    "        Si se debe intentar usar GPU para acelerar algunos c√°lculos.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if country_names is None:\n",
    "        country_names = [f\"Pa√≠s {i}\" for i in range(n)]\n",
    "\n",
    "    if len(country_names) != n:\n",
    "        raise ValueError(f\"La longitud de country_names ({len(country_names)}) no coincide con la dimensi√≥n de X ({n})\")\n",
    "\n",
    "    # Configurar paralelizaci√≥n\n",
    "    if n_jobs is None:\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "    \n",
    "    # Verificar disponibilidad de GPU\n",
    "    gpu_available = torch.cuda.is_available() and use_gpu\n",
    "    X_clean = X\n",
    "\n",
    "    denom = X_clean.sum(axis=0, dtype=np.float64)\n",
    "    denom[denom == 0.0] = np.inf\n",
    "    T = (X_clean / denom).astype(np.float64, copy=False)\n",
    "\n",
    "    denominators = np.sum(X, axis=0)\n",
    "\n",
    "    # Acelerar c√°lculos directos con GPU si est√° disponible\n",
    "    if gpu_available:\n",
    "        # Transferir datos a GPU\n",
    "        X_gpu = torch.tensor(X_clean, device='cuda', dtype=torch.float32)\n",
    "        denom_gpu = torch.tensor(denominators, device='cuda', dtype=torch.float32)\n",
    "        \n",
    "        # Calcular dependencias directas en forma vectorizada\n",
    "        direct_deps = torch.zeros_like(X_gpu)\n",
    "        for i in range(n):\n",
    "            # Evitar divisi√≥n por cero\n",
    "            if denom_gpu[i] > 0:\n",
    "                direct_deps[:, i] = X_gpu[:, i] / denom_gpu[i]\n",
    "        \n",
    "        # Transferir resultados de vuelta a CPU\n",
    "        direct_dependencies = direct_deps.cpu().numpy()\n",
    "        \n",
    "        # Usar estas dependencias directas precalculadas en el procesamiento posterior\n",
    "        # (Aunque en esta implementaci√≥n seguimos calcul√°ndolas en process_country_pair para\n",
    "        # mantener cambios m√≠nimos en el c√≥digo)\n",
    "\n",
    "    # Estructura de resultados extendida\n",
    "    results = {\n",
    "        'dependencies': [],\n",
    "        'top_dependencies': [],\n",
    "        'avg_dependencies': {},\n",
    "        'length_distribution': np.zeros(max_possible_length),\n",
    "        'critical_intermediaries': {},     # Intermediarios cr√≠ticos por relaci√≥n\n",
    "        'intermediary_frequency': {},      # Frecuencia de pa√≠ses como intermediarios\n",
    "        'critical_paths': [],              # Rutas cr√≠ticas completas\n",
    "        'intermediary_strength': {}        # Fuerza de cada pa√≠s como intermediario\n",
    "    }\n",
    "    \n",
    "    # Inicializar contadores para intermediarios\n",
    "    for country in country_names:\n",
    "        results['intermediary_frequency'][country] = 0\n",
    "        results['intermediary_strength'][country] = 0.0\n",
    "\n",
    "    # Preparar pares de pa√≠ses para procesamiento paralelo \n",
    "    # Mantenemos la misma estructura de iteraci√≥n del c√≥digo original\n",
    "    # Primero por importador (i) y luego por exportador (j)\n",
    "        # Preparar pares de pa√≠ses (sin tqdm)\n",
    "    country_pairs = [(i, j) for i in range(n) for j in range(n) if i != j]\n",
    "\n",
    "    # Procesar pares de pa√≠ses en paralelo (sin barra de progreso)\n",
    "    with Parallel(n_jobs=n_jobs) as parallel:\n",
    "        pair_results = parallel(\n",
    "            delayed(process_country_pair)(\n",
    "                i, j, X_clean, denom, country_names, \n",
    "                max_possible_length, convergence_threshold, path_strength_threshold,\n",
    "                T  # <-- NUEVO ARGUMENTO\n",
    "            )\n",
    "            for i, j in country_pairs\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "    # Agrupar resultados por pa√≠s importador\n",
    "    results_by_importer = {}\n",
    "    for res in pair_results:\n",
    "        importer = res['result']['importador']\n",
    "        if importer not in results_by_importer:\n",
    "            results_by_importer[importer] = []\n",
    "        results_by_importer[importer].append(res)\n",
    "    \n",
    "    # Recolectar critical paths de todos los pares para ordenarlos despu√©s\n",
    "    all_critical_paths = []\n",
    "    \n",
    "    # Procesar los resultados manteniendo el mismo orden que el c√≥digo original\n",
    "    for i in range(n):\n",
    "        importer = country_names[i]\n",
    "        total_dep = 0.0\n",
    "        num_deps = 0\n",
    "        \n",
    "        if importer in results_by_importer:\n",
    "            for res in results_by_importer[importer]:\n",
    "                # Agregar a dependencies\n",
    "                results['dependencies'].append(res['result'])\n",
    "                \n",
    "                # Agregar a top_dependencies\n",
    "                results['top_dependencies'].append(res['top_dependency'])\n",
    "                \n",
    "                # Actualizar critical_intermediaries\n",
    "                results['critical_intermediaries'][res['pair_key']] = res['significant_paths']\n",
    "                \n",
    "                # Recolectar critical paths\n",
    "                all_critical_paths.extend(res['significant_paths'])\n",
    "                \n",
    "                # Actualizar length_distribution si convergi√≥\n",
    "                if res['length_converged'] > 1:\n",
    "                    results['length_distribution'][res['length_converged'] - 1] += 1\n",
    "                \n",
    "                # Actualizar dependencia promedio\n",
    "                total_dep += res['result']['dependencia_total']\n",
    "                num_deps += 1\n",
    "                \n",
    "                # Actualizar estad√≠sticas de intermediarios\n",
    "                for path in res['significant_paths']:\n",
    "                    for idx, interm in enumerate(path['intermediarios']):\n",
    "                        # Incrementar frecuencia\n",
    "                        results['intermediary_frequency'][interm] += 1\n",
    "                        \n",
    "                        # Incrementar fuerza ponderada\n",
    "                        weight_factor = 1.0 / (idx + 1)\n",
    "                        results['intermediary_strength'][interm] += path['fuerza'] * weight_factor\n",
    "        \n",
    "        # Guardar dependencia promedio para este importador\n",
    "        results['avg_dependencies'][importer] = total_dep / num_deps if num_deps > 0 else 0\n",
    "    \n",
    "    # A√±adir y ordenar los critical paths (igual que el original)\n",
    "    results['critical_paths'] = all_critical_paths\n",
    "    \n",
    "    # Ordenar top dependencies\n",
    "    results['top_dependencies'].sort(key=lambda x: x[4], reverse=True)\n",
    "    results['top_dependencies'] = results['top_dependencies'][:90]\n",
    "    \n",
    "    # Ordenar critical_paths por fuerza\n",
    "    results['critical_paths'].sort(key=lambda x: x['fuerza'], reverse=True)\n",
    "    \n",
    "    # Calcular m√©tricas de centralidad para intermediarios\n",
    "    results['intermediary_centrality'] = calculate_intermediary_centrality(\n",
    "        results['intermediary_frequency'], \n",
    "        results['intermediary_strength'],\n",
    "        country_names\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Para mantener compatibilidad, redefinimos la funci√≥n original\n",
    "# para que utilice la versi√≥n paralelizada\n",
    "def calculate_all_dependencies(X, country_names=None, convergence_threshold=0.01, \n",
    "                              max_possible_length=3, threshold_pct=0.01, \n",
    "                              path_strength_threshold=0.001):\n",
    "    \"\"\"\n",
    "    Calcula todas las dependencias entre pa√≠ses con an√°lisis de intermediarios cr√≠ticos.\n",
    "    \n",
    "    Esta funci√≥n mantiene EXACTAMENTE la misma firma y resultados que la original,\n",
    "    pero utiliza internamente paralelizaci√≥n y GPU para acelerar los c√°lculos.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray\n",
    "        Matriz de comercio\n",
    "    country_names : list, opcional\n",
    "        Nombres de los pa√≠ses\n",
    "    convergence_threshold : float, default=0.01\n",
    "        Umbral para determinar la convergencia\n",
    "    max_possible_length : int, default=5\n",
    "        Longitud m√°xima de caminos a considerar\n",
    "    threshold_pct : float, default=0.01\n",
    "        Umbral para filtrar valores de comercio insignificantes (porcentaje)\n",
    "    path_strength_threshold : float, default=0.001\n",
    "        Umbral m√≠nimo para considerar una ruta como significativa\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con todos los resultados del an√°lisis\n",
    "    \"\"\"\n",
    "    # Determinar si usar paralelizaci√≥n basado en el tama√±o del problema\n",
    "    use_parallel = X.shape[0] > 5  # Para matrices muy peque√±as no vale la pena paralelizar\n",
    "    \n",
    "    # Verificar disponibilidad de GPU\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    # Aqu√≠ agregas el segundo log\n",
    "    #print(f\"Usando paralelizaci√≥n: {use_parallel}, GPU disponible: {use_gpu}\")\n",
    "    #if use_gpu:\n",
    "    #    print(f\"GPU en uso: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Configurar n√∫mero de trabajos para paralelizaci√≥n\n",
    "    n_countries = X.shape[0]\n",
    "    n_jobs = min(multiprocessing.cpu_count(), n_countries)  # Limitar al n√∫mero de pa√≠ses\n",
    "    \n",
    "    \n",
    "    if use_parallel:\n",
    "        # Usar la versi√≥n paralelizada\n",
    "        return calculate_all_dependencies_parallel(\n",
    "            X, country_names, convergence_threshold, \n",
    "            max_possible_length, path_strength_threshold,\n",
    "            n_jobs=n_jobs, use_gpu=use_gpu, debug_mode=False\n",
    "        )\n",
    "    else:\n",
    "        # Para matrices muy peque√±as, usar un solo proceso\n",
    "        return calculate_all_dependencies_parallel(\n",
    "            X, country_names, convergence_threshold, \n",
    "            max_possible_length, path_strength_threshold,\n",
    "            n_jobs=1, use_gpu=use_gpu, debug_mode=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar y guardar resultados de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 industrias en matrices_comercio: ['154 Manufacturing services on physical inputs', '155 Maintenance and repair services n.i.e.', '156 Transport', '157 Travel', '158 Construction', '159 Insurance and pension services', '160 Financial services', '161 Charges for use of intellectual property', '162 Telecom, computer, information services', '163 Other business services', '164 Heritage and recreational services', '165 Health services', '166 Education services', '167 Government goods and services n.i.e.', '168 Services not allocated', '169 Trade-related services', '170 Other personal services', 'Accumulators primary cells and batteries', 'Agricultural and forestry machinery', 'Aircraft and spacecraft', 'Animal feed ingredients and pet foods', 'Articles of concrete cement and plaster', 'Automobile bodies trailers & semi-trailers', 'Bakery products', 'Basic chemicals except fertilizers', 'Basic iron and steel', 'Basic precious and non-ferrous metals', 'Bearings gears gearing & driving elements', 'Beverages, nec', 'Bicycles and invalid carriages', \"Builders' carpentry and joinery\", 'Building and repairing of ships', 'Building/repairing of pleasure/sport. boats', 'Carpets and rugs', 'Cement lime and plaster', 'Cereal products', 'Cocoa and cocoa products', 'Cocoa chocolate and sugar confectionery', 'Coke oven products', 'Cordage rope twine and netting', 'Corn', 'Corrugated paper and paperboard', 'Cotton', 'Cutlery hand tools and general hardware', 'Cutting shaping & finishing of stone', 'Dairy products', 'Distilling rectifying & blending of spirits', 'Domestic appliances n.e.c.', 'Dressing & dyeing of fur; processing of fur', 'Eggs']\n"
     ]
    }
   ],
   "source": [
    "# Filtrar para obtener solo las primeras 5 industrias\n",
    "matrices_comercio = {k: matrices_comercio[k] for k in list(matrices_comercio.keys())[:50]}\n",
    "\n",
    "# Verificaci√≥n: imprime las primeras 5 claves\n",
    "print(\"Primeras 5 industrias en matrices_comercio:\", list(matrices_comercio.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 170 industrias...\n",
      "‚úì Completadas: 170/170\n",
      "================================================================================\n",
      "‚úÖ Procesamiento completado: 170/170 industrias\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para guardar todos los resultados\n",
    "all_results = {}\n",
    "\n",
    "# Validaci√≥n inicial\n",
    "if not matrices_comercio:\n",
    "    raise ValueError(\"‚ùå matrices_comercio est√° vac√≠o. Verifica crear_matriz_comercio_optimizado()\")\n",
    "\n",
    "total_industrias = len(matrices_comercio)\n",
    "completadas = 0\n",
    "saltadas = []\n",
    "print(f\"Procesando {total_industrias} industrias...\")\n",
    "\n",
    "# Procesar cada industria\n",
    "for industry, mat in matrices_comercio.items():\n",
    "    try:\n",
    "        # Limpiar matriz\n",
    "        mat_clean = eliminar_filas_columnas_cero(mat)\n",
    "        \n",
    "        # Si la matriz limpia est√° vac√≠a o es muy peque√±a, continuamos con la siguiente\n",
    "        if mat_clean.shape[0] < 2:\n",
    "            saltadas.append(industry)\n",
    "            continue\n",
    "        \n",
    "        # Convertir a numpy array y obtener nombres de pa√≠ses\n",
    "        X = mat_clean.values\n",
    "        country_names = mat_clean.columns.tolist()\n",
    "\n",
    "        # Calcular dependencias\n",
    "        results = calculate_all_dependencies(X, country_names)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        all_results[industry] = {\n",
    "            'results': results,\n",
    "            'country_names': country_names,\n",
    "            'matrix_shape': mat_clean.shape\n",
    "        }\n",
    "\n",
    "        # Actualizar contador y mostrarlo en la misma l√≠nea\n",
    "        completadas += 1\n",
    "        print(f\"‚úì Completadas: {completadas}/{total_industrias}\", end=\"\\r\", flush=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error en industria '{industry}': {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Procesamiento completado: {completadas}/{total_industrias} industrias\")\n",
    "if saltadas:\n",
    "    print(f\"‚ö†Ô∏è Industrias saltadas ({len(saltadas)}): {', '.join(saltadas[:5])}{'...' if len(saltadas) > 5 else ''}\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar y guadar datos de intermediarios Cr√≠ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_intermediaries(results, top_n=10):\n",
    "    \"\"\"\n",
    "    Obtiene los pa√≠ses m√°s importantes como intermediarios.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados del an√°lisis con intermediarios\n",
    "    top_n : int\n",
    "        N√∫mero de pa√≠ses a mostrar\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Lista de tuplas (pa√≠s, score, frecuencia, fuerza) ordenadas por importancia\n",
    "    \"\"\"\n",
    "    # La estructura de intermediary_centrality ha cambiado en la nueva implementaci√≥n\n",
    "    # Ahora es una lista de tuplas (pa√≠s, frecuencia, fuerza, score_combinado)\n",
    "    if isinstance(results['intermediary_centrality'], list):\n",
    "        # Nueva implementaci√≥n: ya est√° ordenada por score combinado\n",
    "        return results['intermediary_centrality'][:top_n]\n",
    "    else:\n",
    "        # Implementaci√≥n anterior (por compatibilidad)\n",
    "        centrality_scores = [(country, metrics) \n",
    "                            for country, metrics in results['intermediary_centrality'].items()]\n",
    "        centrality_scores.sort(key=lambda x: x[1]['centrality_score'], reverse=True)\n",
    "        return centrality_scores[:top_n]\n",
    "\n",
    "def analyze_country_intermediary_role(results, country):\n",
    "    \"\"\"\n",
    "    Analiza el papel de un pa√≠s espec√≠fico como intermediario.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados del an√°lisis con intermediarios\n",
    "    country : str\n",
    "        Pa√≠s a analizar\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Informaci√≥n detallada sobre el rol del pa√≠s como intermediario\n",
    "    \"\"\"\n",
    "    # Verificar si el pa√≠s existe en los resultados\n",
    "    if isinstance(results['intermediary_centrality'], list):\n",
    "        # Nueva implementaci√≥n - lista de tuplas\n",
    "        country_entry = next((entry for entry in results['intermediary_centrality'] \n",
    "                             if entry[0] == country), None)\n",
    "        \n",
    "        if country_entry is None:\n",
    "            return {\"error\": f\"El pa√≠s {country} no est√° en los resultados\"}\n",
    "            \n",
    "        # Extraer m√©tricas\n",
    "        centrality = {\n",
    "            \"frequency\": country_entry[1],\n",
    "            \"strength\": country_entry[2],\n",
    "            \"centrality_score\": country_entry[3]\n",
    "        }\n",
    "    else:\n",
    "        # Implementaci√≥n anterior\n",
    "        if country not in results['intermediary_centrality']:\n",
    "            return {\"error\": f\"El pa√≠s {country} no est√° en los resultados\"}\n",
    "        centrality = results['intermediary_centrality'][country]\n",
    "    \n",
    "    # Encontrar las rutas m√°s importantes donde este pa√≠s act√∫a como intermediario\n",
    "    top_paths = []\n",
    "    for path in results['critical_paths']:\n",
    "        if country in path['intermediarios']:\n",
    "            top_paths.append(path)\n",
    "    \n",
    "    # Ordenar por fuerza del camino\n",
    "    top_paths.sort(key=lambda x: x['fuerza'], reverse=True)\n",
    "    \n",
    "    # Filtrar los 10 caminos m√°s importantes\n",
    "    top_paths = top_paths[:10]\n",
    "    \n",
    "    return {\n",
    "        \"metrics\": centrality,\n",
    "        \"top_paths\": top_paths,\n",
    "        \"role_summary\": {\n",
    "            \"total_paths\": len(top_paths),\n",
    "            \"average_path_strength\": sum(p['fuerza'] for p in top_paths) / len(top_paths) if top_paths else 0,\n",
    "            \"max_path_strength\": max(p['fuerza'] for p in top_paths) if top_paths else 0,\n",
    "            \"unique_exporters\": len(set(p['exportador'] for p in top_paths)),\n",
    "            \"unique_importers\": len(set(p['importador'] for p in top_paths))\n",
    "        }\n",
    "    }\n",
    "\n",
    "def summarize_country_dependencies(results, country, top_n=5):\n",
    "    \"\"\"\n",
    "    Genera un resumen de las dependencias comerciales de un pa√≠s espec√≠fico.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados del an√°lisis de dependencias\n",
    "    country : str\n",
    "        Pa√≠s a analizar\n",
    "    top_n : int\n",
    "        N√∫mero de dependencias principales a mostrar\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Resumen de dependencias del pa√≠s\n",
    "    \"\"\"\n",
    "    # Dependencias como importador (otros pa√≠ses exportan a este pa√≠s)\n",
    "    import_dependencies = []\n",
    "    for dep in results['dependencies']:\n",
    "        if dep['importador'] == country:\n",
    "            import_dependencies.append(dep)\n",
    "    \n",
    "    # Ordenar por dependencia total\n",
    "    import_dependencies.sort(key=lambda x: x['dependencia_total'], reverse=True)\n",
    "    \n",
    "    # Dependencias como exportador (este pa√≠s exporta a otros)\n",
    "    export_dependencies = []\n",
    "    for dep in results['dependencies']:\n",
    "        if dep['exportador'] == country:\n",
    "            export_dependencies.append(dep)\n",
    "    \n",
    "    # Ordenar por dependencia total\n",
    "    export_dependencies.sort(key=lambda x: x['dependencia_total'], reverse=True)\n",
    "    \n",
    "    # Calcular dependencia promedio\n",
    "    avg_dependency = results['avg_dependencies'].get(country, 0)\n",
    "    \n",
    "    # Analizar el papel como intermediario\n",
    "    intermediary_role = None\n",
    "    if isinstance(results['intermediary_centrality'], list):\n",
    "        # Nueva implementaci√≥n\n",
    "        intermediary_info = next((x for x in results['intermediary_centrality'] if x[0] == country), None)\n",
    "        if intermediary_info:\n",
    "            intermediary_role = {\n",
    "                \"frequency\": intermediary_info[1],\n",
    "                \"strength\": intermediary_info[2],\n",
    "                \"centrality_score\": intermediary_info[3],\n",
    "                \"rank\": next((i+1 for i, x in enumerate(results['intermediary_centrality']) \n",
    "                             if x[0] == country), None)\n",
    "            }\n",
    "    else:\n",
    "        # Implementaci√≥n anterior\n",
    "        if country in results['intermediary_centrality']:\n",
    "            intermediary_role = results['intermediary_centrality'][country]\n",
    "            # Calcular rango\n",
    "            countries_sorted = sorted(results['intermediary_centrality'].keys(), \n",
    "                                     key=lambda x: results['intermediary_centrality'][x]['centrality_score'],\n",
    "                                     reverse=True)\n",
    "            intermediary_role[\"rank\"] = countries_sorted.index(country) + 1\n",
    "    \n",
    "    return {\n",
    "        \"country\": country,\n",
    "        \"avg_dependency\": avg_dependency,\n",
    "        \"top_import_dependencies\": import_dependencies[:top_n],\n",
    "        \"top_export_dependencies\": export_dependencies[:top_n],\n",
    "        \"total_import_dependencies\": len(import_dependencies),\n",
    "        \"total_export_dependencies\": len(export_dependencies),\n",
    "        \"intermediary_role\": intermediary_role\n",
    "    }\n",
    "\n",
    "def identify_critical_trade_relationships(results, threshold=0.7, min_paths=3):\n",
    "    \"\"\"\n",
    "    Identifica relaciones comerciales cr√≠ticas con alta dependencia.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Resultados del an√°lisis de dependencias\n",
    "    threshold : float\n",
    "        Umbral de dependencia para considerar una relaci√≥n como cr√≠tica\n",
    "    min_paths : int\n",
    "        N√∫mero m√≠nimo de caminos alternativos para evitar criticidad\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Lista de relaciones cr√≠ticas\n",
    "    \"\"\"\n",
    "    critical_relationships = []\n",
    "    \n",
    "    # Analizar cada dependencia\n",
    "    for dep in results['dependencies']:\n",
    "        if dep['dependencia_total'] >= threshold:\n",
    "            # Buscar caminos alternativos\n",
    "            pair_key = f\"{dep['exportador']}->{dep['importador']}\"\n",
    "            alternative_paths = []\n",
    "            \n",
    "            if pair_key in results['critical_intermediaries']:\n",
    "                alternative_paths = results['critical_intermediaries'][pair_key]\n",
    "            \n",
    "            # Si hay pocos caminos alternativos, es una relaci√≥n cr√≠tica\n",
    "            if len(alternative_paths) < min_paths:\n",
    "                critical_relationships.append({\n",
    "                    \"exportador\": dep['exportador'],\n",
    "                    \"importador\": dep['importador'],\n",
    "                    \"dependencia_total\": dep['dependencia_total'],\n",
    "                    \"dependencia_directa\": dep['dependencia_directa'],\n",
    "                    \"caminos_alternativos\": len(alternative_paths),\n",
    "                    \"criticidad\": 1.0 - (len(alternative_paths) / min_paths) \n",
    "                                     if min_paths > 0 else 1.0\n",
    "                })\n",
    "    \n",
    "    # Ordenar por criticidad\n",
    "    critical_relationships.sort(key=lambda x: x['criticidad'], reverse=True)\n",
    "    \n",
    "    return critical_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo Dataframes para guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame guardado correctamente en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\dependencias2022_borrar.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dependencies_dataframe(all_results):\n",
    "    \"\"\"\n",
    "    Crea un DataFrame con los resultados de dependencias para todas las industrias.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_results : dict\n",
    "        Diccionario con los resultados por industria\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con las columnas: industria, importador, exportador, \n",
    "        dependencia_total, dependencia_directa, dependencia_indirecta, longitud_optima\n",
    "    \"\"\"\n",
    "    # Lista para almacenar los datos de todas las industrias\n",
    "    all_data = []\n",
    "    \n",
    "    # Procesar cada industria\n",
    "    for industry, data in all_results.items():\n",
    "        # Obtener los resultados de esta industria\n",
    "        industry_results = data['results']['dependencies']\n",
    "        \n",
    "        # A√±adir cada fila de resultados\n",
    "        for result in industry_results:\n",
    "            row = {\n",
    "                'industria': industry,\n",
    "                'importador': result['importador'],\n",
    "                'exportador': result['exportador'],\n",
    "                'dependencia_total': result['dependencia_total'],\n",
    "                'dependencia_directa': result['dependencia_directa'],\n",
    "                'dependencia_indirecta': result['dependencia_indirecta'],\n",
    "                'trade_value': result['trade_value'],\n",
    "                'longitud_optima': result['longitud_optima']\n",
    "            }\n",
    "            all_data.append(row)\n",
    "    \n",
    "    # Crear el DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Ordenar el DataFrame\n",
    "    df = df.sort_values(['industria', 'dependencia_total'], ascending=[True, False])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso:\n",
    "df = create_dependencies_dataframe(all_results)\n",
    "\n",
    "# Definir el nuevo mapeo de nombres de columnas\n",
    "nuevo_nombres = {\n",
    "    'industria': 'industry',\n",
    "    'importador': 'dependent_country',\n",
    "    'exportador': 'supplier_country',\n",
    "    'dependencia_total': 'dependency_value',\n",
    "    'dependencia_directa': 'direct_dependency',\n",
    "    'dependencia_indirecta': 'indirect_dependency',\n",
    "    'trade_value': 'trade_value',\n",
    "    'longitud_optima': 'longitud_optima'\n",
    "}\n",
    "\n",
    "# Renombrar las columnas\n",
    "df = df.rename(columns=nuevo_nombres)\n",
    "\n",
    "# Rutas (evitamos espacios en nombres de carpetas)\n",
    "base_path = Path.cwd().parent.parent\n",
    "target_directory = base_path / \"data\" / \"processed\" / \"dependencias_consolidadas\"\n",
    "\n",
    "ruta_archivo = target_directory / f\"dependencias{anio}_borrar.csv.gz\"\n",
    "\n",
    "\n",
    "# Guardar como gzip\n",
    "with gzip.open(ruta_archivo, 'wt', encoding='utf-8') as f:\n",
    "    df.to_csv(f, sep=\";\", index=False)\n",
    "\n",
    "print(f\"DataFrame guardado correctamente en: {ruta_archivo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AN√ÅLISIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_dependencia_trazable(\n",
    "    matrices_comercio, \n",
    "    industry: str,\n",
    "    exportador_iso3: str,\n",
    "    importador_iso3: str,\n",
    "    country_names=None,\n",
    "    convergence_threshold=0.01,\n",
    "    max_possible_length=3,\n",
    "    path_strength_threshold=0.001,\n",
    "    apply_cleanup=True,  # ‚Üê NUEVO\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Calcula la dependencia de un par exportador-importador en una industria espec√≠fica,\n",
    "    mostrando el RASTRO COMPLETO de cada c√°lculo paso a paso.\n",
    "    \n",
    "    AHORA TAMBI√âN MUESTRA de d√≥nde salen las FUERZAS en dependencias indirectas:\n",
    "    - Valores brutos de comercio X\n",
    "    - Denominadores (importaciones totales)\n",
    "    - C√°lculo de cada transici√≥n T\n",
    "    - Producto final\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrices_comercio : dict\n",
    "        Diccionario de matrices por industria (salida de crear_matriz_comercio_optimizado)\n",
    "    industry : str\n",
    "        Nombre de la industria a analizar\n",
    "    exportador_iso3 : str\n",
    "        C√≥digo ISO3 del pa√≠s exportador\n",
    "    importador_iso3 : str\n",
    "        C√≥digo ISO3 del pa√≠s importador\n",
    "    country_names : list, opcional\n",
    "        Lista de nombres de pa√≠ses (si None, usa los √≠ndices de la matriz)\n",
    "    convergence_threshold : float\n",
    "        Umbral de convergencia\n",
    "    max_possible_length : int\n",
    "        Longitud m√°xima de caminos\n",
    "    path_strength_threshold : float\n",
    "        Umbral m√≠nimo de fuerza de camino\n",
    "    verbose : bool\n",
    "        Si imprimir el an√°lisis detallado\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict con toda la informaci√≥n y rastro de c√°lculos\n",
    "    \"\"\"\n",
    "    \n",
    "    # VALIDACIONES\n",
    "    if industry not in matrices_comercio:\n",
    "        raise ValueError(f\"Industria '{industry}' no encontrada. Disponibles: {list(matrices_comercio.keys())[:5]}...\")\n",
    "    \n",
    "    mat = matrices_comercio[industry]\n",
    "    \n",
    "    if apply_cleanup:\n",
    "        mat = eliminar_filas_columnas_cero(mat)\n",
    "    \n",
    "    # Obtener √≠ndices de pa√≠ses\n",
    "    try:\n",
    "        j_idx = list(mat.index).index(exportador_iso3)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Exportador '{exportador_iso3}' no en industria '{industry}'\")\n",
    "    \n",
    "    try:\n",
    "        i_idx = list(mat.columns).index(importador_iso3)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Importador '{importador_iso3}' no en industria '{industry}'\")\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    X = mat.values.astype(np.float64)\n",
    "    pais_names = list(mat.columns)\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    if country_names is None:\n",
    "        country_names = pais_names\n",
    "    \n",
    "    # =====================================================\n",
    "    # RASTRO DE C√ÅLCULOS\n",
    "    # =====================================================\n",
    "    trace = {\n",
    "        'industry': industry,\n",
    "        'exportador': exportador_iso3,\n",
    "        'importador': importador_iso3,\n",
    "        'pasos': []\n",
    "    }\n",
    "    \n",
    "    # PASO 1: MATRIZ DE TRANSICI√ìN\n",
    "    # ============================\n",
    "    denom = X.sum(axis=0, dtype=np.float64)\n",
    "    denom_safe = denom.copy()\n",
    "    denom_safe[denom_safe == 0.0] = np.inf\n",
    "    T = (X / denom_safe).astype(np.float64)\n",
    "    \n",
    "    trace['pasos'].append({\n",
    "        'fase': '1. MATRIZ DE TRANSICI√ìN',\n",
    "        'descripcion': f'T[a,b] = X[a,b] / (suma de importaciones de b)',\n",
    "        'denominadores': {pais_names[k]: float(denom[k]) for k in range(n)},\n",
    "        'matriz_T_forma': T.shape\n",
    "    })\n",
    "    \n",
    "    # PASO 2: DEPENDENCIA DIRECTA (L=1)\n",
    "    # ==================================\n",
    "    trade_value = X[j_idx, i_idx]\n",
    "    denom_i = denom[i_idx]\n",
    "    direct_dependency = (X[j_idx, i_idx] / denom_i) if denom_i > 0 else 0.0\n",
    "    \n",
    "    trace['pasos'].append({\n",
    "        'fase': '2. DEPENDENCIA DIRECTA (L=1)',\n",
    "        'calculo': f'{exportador_iso3} ‚Üí {importador_iso3}',\n",
    "        'valor_comercio': float(trade_value),\n",
    "        'formula': f'X[{j_idx},{i_idx}] / denom[{i_idx}]',\n",
    "        'valor_numerador': float(X[j_idx, i_idx]),\n",
    "        'denominador': float(denom_i),\n",
    "        'resultado': float(direct_dependency)\n",
    "    })\n",
    "    \n",
    "    total_dependency = direct_dependency\n",
    "    dependencies_by_length = {1: direct_dependency}\n",
    "    all_paths = []\n",
    "    \n",
    "    # PASO 3: DEPENDENCIA INDIRECTA L=2\n",
    "    # ==================================\n",
    "    if max_possible_length >= 2:\n",
    "        trace_l2 = {\n",
    "            'fase': '3. DEPENDENCIA INDIRECTA (L=2)',\n",
    "            'formula': f'sum_k [ T[{j_idx},k] * T[k,{i_idx}] ] para k != {j_idx}, {i_idx}',\n",
    "            'intermediarios_evaluados': [],\n",
    "            'suma_total': 0.0\n",
    "        }\n",
    "        \n",
    "        di_l2 = 0.0\n",
    "        row_j = T[j_idx, :]\n",
    "        col_i = T[:, i_idx]\n",
    "        \n",
    "        for k in range(n):\n",
    "            if k != j_idx and k != i_idx:\n",
    "                # PASO A: {exportador} ‚Üí {intermediario}\n",
    "                x_jk = X[j_idx, k]\n",
    "                denom_k = denom[k]\n",
    "                t_jk = row_j[k]\n",
    "                \n",
    "                # PASO B: {intermediario} ‚Üí {importador}\n",
    "                x_ki = X[k, i_idx]\n",
    "                denom_i_paso2 = denom[i_idx]\n",
    "                t_ki = col_i[k]\n",
    "                \n",
    "                # Producto\n",
    "                producto = t_jk * t_ki\n",
    "                \n",
    "                trace_l2['intermediarios_evaluados'].append({\n",
    "                    'intermediario': pais_names[k],\n",
    "                    'paso_1_exportador_a_intermediario': {\n",
    "                        'transicion': f'{exportador_iso3} ‚Üí {pais_names[k]}',\n",
    "                        'valor_comercio_X': float(x_jk),\n",
    "                        'importaciones_totales_de': f'{pais_names[k]}',\n",
    "                        'denominador': float(denom_k),\n",
    "                        'T_valor': float(t_jk),\n",
    "                        'formula': f'X[{j_idx},{k}] / denom[{k}] = {x_jk:.10f} / {denom_k:.10f} = {t_jk:.10f}'\n",
    "                    },\n",
    "                    'paso_2_intermediario_a_importador': {\n",
    "                        'transicion': f'{pais_names[k]} ‚Üí {importador_iso3}',\n",
    "                        'valor_comercio_X': float(x_ki),\n",
    "                        'importaciones_totales_de': f'{importador_iso3}',\n",
    "                        'denominador': float(denom_i_paso2),\n",
    "                        'T_valor': float(t_ki),\n",
    "                        'formula': f'X[{k},{i_idx}] / denom[{i_idx}] = {x_ki:.10f} / {denom_i_paso2:.10f} = {t_ki:.10f}'\n",
    "                    },\n",
    "                    'producto_fuerza': {\n",
    "                        'formula': f'T[{j_idx},{k}] √ó T[{k},{i_idx}] = {t_jk:.10f} √ó {t_ki:.10f}',\n",
    "                        'resultado': float(producto)\n",
    "                    },\n",
    "                    'pasa_threshold': producto > path_strength_threshold\n",
    "                })\n",
    "                \n",
    "                di_l2 += producto\n",
    "                \n",
    "                if producto > path_strength_threshold:\n",
    "                    all_paths.append({\n",
    "                        'camino': f\"{exportador_iso3} ‚Üí {pais_names[k]} ‚Üí {importador_iso3}\",\n",
    "                        'longitud': 2,\n",
    "                        'intermediarios': [pais_names[k]],\n",
    "                        'fuerza': float(producto),\n",
    "                        'desglose_pasos': [\n",
    "                            {\n",
    "                                'de': exportador_iso3,\n",
    "                                'a': pais_names[k],\n",
    "                                'valor_X': float(x_jk),\n",
    "                                'importaciones_totales': float(denom_k),\n",
    "                                'T_valor': float(t_jk),\n",
    "                                'formula': f'{x_jk:.10f} / {denom_k:.10f} = {t_jk:.10f}'\n",
    "                            },\n",
    "                            {\n",
    "                                'de': pais_names[k],\n",
    "                                'a': importador_iso3,\n",
    "                                'valor_X': float(x_ki),\n",
    "                                'importaciones_totales': float(denom_i_paso2),\n",
    "                                'T_valor': float(t_ki),\n",
    "                                'formula': f'{x_ki:.10f} / {denom_i_paso2:.10f} = {t_ki:.10f}'\n",
    "                            }\n",
    "                        ],\n",
    "                        'pasos_transicion': [\n",
    "                            (exportador_iso3, pais_names[k], float(t_jk)),\n",
    "                            (pais_names[k], importador_iso3, float(t_ki))\n",
    "                        ]\n",
    "                    })\n",
    "        \n",
    "        trace_l2['suma_total'] = float(di_l2)\n",
    "        trace['pasos'].append(trace_l2)\n",
    "        \n",
    "        dependencies_by_length[2] = float(di_l2)\n",
    "        total_dependency += di_l2\n",
    "    \n",
    "    # PASO 4+: DEPENDENCIA INDIRECTA L>=3\n",
    "    # ====================================\n",
    "    if max_possible_length >= 3:\n",
    "        middle = [k for k in range(n) if k != j_idx and k != i_idx]\n",
    "        \n",
    "        for L in range(3, max_possible_length + 1):\n",
    "            trace_lx = {\n",
    "                'fase': f'4.{L-2}. DEPENDENCIA INDIRECTA (L={L})',\n",
    "                'longitud': L,\n",
    "                'num_combinaciones': len(list(combinations(middle, L-1))),\n",
    "                'caminos_significativos': [],\n",
    "                'suma_total': 0.0\n",
    "            }\n",
    "            \n",
    "            di_lx = 0.0\n",
    "            \n",
    "            for interms in combinations(middle, L-1):\n",
    "                path_seq = (j_idx,) + interms + (i_idx,)\n",
    "                \n",
    "                # Calcular producto a lo largo del camino CON DESGLOSE\n",
    "                prod = 1.0\n",
    "                pasos_camino = []\n",
    "                desglose_pasos = []\n",
    "                \n",
    "                for a, b in zip(path_seq[:-1], path_seq[1:]):\n",
    "                    x_ab = X[a, b]\n",
    "                    denom_b = denom[b]\n",
    "                    w = T[a, b]\n",
    "                    \n",
    "                    desglose_pasos.append({\n",
    "                        'de': pais_names[a],\n",
    "                        'a': pais_names[b],\n",
    "                        'valor_X': float(x_ab),\n",
    "                        'importaciones_totales': float(denom_b),\n",
    "                        'T_valor': float(w),\n",
    "                        'formula': f'{x_ab:.10f} / {denom_b:.10f} = {w:.10f}'\n",
    "                    })\n",
    "                    \n",
    "                    pasos_camino.append((pais_names[a], pais_names[b], float(w)))\n",
    "                    if w == 0.0:\n",
    "                        prod = 0.0\n",
    "                        break\n",
    "                    prod *= w\n",
    "                \n",
    "                di_lx += prod\n",
    "                \n",
    "                if prod > path_strength_threshold:\n",
    "                    # Construir f√≥rmula del producto\n",
    "                    formula_prod = ' √ó '.join([f'{paso[\"T_valor\"]:.10f}' for paso in desglose_pasos])\n",
    "                    \n",
    "                    trace_lx['caminos_significativos'].append({\n",
    "                        'camino': ' ‚Üí '.join([pais_names[idx] for idx in path_seq]),\n",
    "                        'intermediarios': [pais_names[idx] for idx in interms],\n",
    "                        'pasos_desglose': desglose_pasos,\n",
    "                        'formula_producto': formula_prod,\n",
    "                        'producto': float(prod)\n",
    "                    })\n",
    "                    \n",
    "                    all_paths.append({\n",
    "                        'camino': ' ‚Üí '.join([pais_names[idx] for idx in path_seq]),\n",
    "                        'longitud': L,\n",
    "                        'intermediarios': [pais_names[idx] for idx in interms],\n",
    "                        'fuerza': float(prod),\n",
    "                        'desglose_pasos': desglose_pasos,\n",
    "                        'pasos_transicion': pasos_camino\n",
    "                    })\n",
    "            \n",
    "            trace_lx['suma_total'] = float(di_lx)\n",
    "            trace['pasos'].append(trace_lx)\n",
    "            \n",
    "            dependencies_by_length[L] = float(di_lx)\n",
    "            total_dependency += di_lx\n",
    "            \n",
    "            # Criterio de convergencia\n",
    "            if L > 1 and di_lx < convergence_threshold:\n",
    "                trace['pasos'].append({\n",
    "                    'fase': 'CONVERGENCIA',\n",
    "                    'mensaje': f'L={L}: contribuci√≥n ({di_lx}) < threshold ({convergence_threshold})',\n",
    "                    'detenido_en': L\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    # RESUMEN FINAL\n",
    "    # =============\n",
    "    trace['resumen'] = {\n",
    "        'dependencia_directa': float(direct_dependency),\n",
    "        'dependencia_indirecta_total': float(total_dependency - direct_dependency),\n",
    "        'dependencia_total': float(total_dependency),\n",
    "        'desglose_por_longitud': {k: float(v) for k, v in dependencies_by_length.items()},\n",
    "        'num_caminos_significativos': len(all_paths),\n",
    "        'valor_comercio': float(trade_value)\n",
    "    }\n",
    "    \n",
    "    trace['caminos'] = sorted(all_paths, key=lambda x: x['fuerza'], reverse=True)\n",
    "    \n",
    "    # IMPRESI√ìN FORMATEADA\n",
    "    # ====================\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"AN√ÅLISIS TRAZABLE DE DEPENDENCIA COMERCIAL CON DESGLOSE DE FUERZAS\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"\\nüìä CONTEXTO:\")\n",
    "        print(f\"   Industria:       {industry}\")\n",
    "        print(f\"   Exportador:      {exportador_iso3}\")\n",
    "        print(f\"   Importador:      {importador_iso3}\")\n",
    "        print(f\"   Valor comercio:  {trade_value:,.2f}\")\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"MATRIZ DE TRANSICI√ìN T\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        print(f\"T[a,b] = (flujo de a hacia b) / (suma total de importaciones de b)\")\n",
    "        print(f\"Dimensiones: {T.shape[0]} pa√≠ses √ó {T.shape[1]} pa√≠ses\")\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"C√ÅLCULO DE DEPENDENCIA\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        \n",
    "        print(f\"\\n1Ô∏è‚É£  DEPENDENCIA DIRECTA (L=1):\")\n",
    "        print(f\"   F√≥rmula: X[{j_idx},{i_idx}] / Œ£(importaciones de {i_idx})\")\n",
    "        print(f\"   Numerador:   {X[j_idx, i_idx]:.10f}\")\n",
    "        print(f\"   Denominador: {denom_i:.10f}\")\n",
    "        print(f\"   ‚ûú Resultado: {direct_dependency:.10f}\")\n",
    "        \n",
    "        if max_possible_length >= 2:\n",
    "            di_l2 = dependencies_by_length.get(2, 0)\n",
    "            print(f\"\\n2Ô∏è‚É£  DEPENDENCIA INDIRECTA (L=2):\")\n",
    "            print(f\"   Caminos evaluados: {n - 2} (intermediarios posibles)\")\n",
    "            \n",
    "            # Mostrar top 5 intermediarios CON DESGLOSE\n",
    "            l2_paths = [p for p in all_paths if p['longitud'] == 2]\n",
    "            if l2_paths:\n",
    "                l2_paths_sorted = sorted(l2_paths, key=lambda x: x['fuerza'], reverse=True)\n",
    "                print(f\"   Top intermediarios CON DESGLOSE DE FUERZAS:\")\n",
    "                for pidx, path in enumerate(l2_paths_sorted[:5], 1):\n",
    "                    inter = path['intermediarios'][0]\n",
    "                    print(f\"\\n      {pidx}. {inter} (Fuerza: {path['fuerza']:.10f})\")\n",
    "                    \n",
    "                    # Paso 1\n",
    "                    paso1 = path['desglose_pasos'][0]\n",
    "                    print(f\"         ‚îî‚îÄ PASO 1: {paso1['de']} ‚Üí {paso1['a']}\")\n",
    "                    print(f\"            X = {paso1['valor_X']:.10f}\")\n",
    "                    print(f\"            Importaciones totales de {paso1['a']} = {paso1['importaciones_totales']:.10f}\")\n",
    "                    print(f\"            T = {paso1['valor_X']:.10f} / {paso1['importaciones_totales']:.10f} = {paso1['T_valor']:.10f}\")\n",
    "                    \n",
    "                    # Paso 2\n",
    "                    paso2 = path['desglose_pasos'][1]\n",
    "                    print(f\"         ‚îî‚îÄ PASO 2: {paso2['de']} ‚Üí {paso2['a']}\")\n",
    "                    print(f\"            X = {paso2['valor_X']:.10f}\")\n",
    "                    print(f\"            Importaciones totales de {paso2['a']} = {paso2['importaciones_totales']:.10f}\")\n",
    "                    print(f\"            T = {paso2['valor_X']:.10f} / {paso2['importaciones_totales']:.10f} = {paso2['T_valor']:.10f}\")\n",
    "                    \n",
    "                    # Producto\n",
    "                    print(f\"         ‚îî‚îÄ FUERZA = {paso1['T_valor']:.10f} √ó {paso2['T_valor']:.10f} = {path['fuerza']:.10f}\")\n",
    "                \n",
    "                if len(l2_paths_sorted) > 5:\n",
    "                    print(f\"\\n      ... y {len(l2_paths_sorted)-5} m√°s\")\n",
    "            \n",
    "            print(f\"\\n   ‚ûú Suma L=2: {di_l2:.10f}\")\n",
    "        \n",
    "        if max_possible_length >= 3:\n",
    "            for L in range(3, max_possible_length + 1):\n",
    "                di_lx = dependencies_by_length.get(L, 0)\n",
    "                lx_paths = [p for p in all_paths if p['longitud'] == L]\n",
    "                print(f\"\\n{L}Ô∏è‚É£  DEPENDENCIA INDIRECTA (L={L}):\")\n",
    "                print(f\"   Combinaciones evaluadas: {len(list(combinations(middle, L-1)))}\")\n",
    "                print(f\"   Caminos significativos encontrados: {len(lx_paths)}\")\n",
    "                \n",
    "                if lx_paths:\n",
    "                    lx_paths_sorted = sorted(lx_paths, key=lambda x: x['fuerza'], reverse=True)\n",
    "                    print(f\"   Top caminos CON DESGLOSE:\")\n",
    "                    for pidx, path in enumerate(lx_paths_sorted[:3], 1):\n",
    "                        print(f\"\\n      {pidx}. {path['camino']}\")\n",
    "                        print(f\"         Fuerza: {path['fuerza']:.10f}\")\n",
    "                        \n",
    "                        for step_idx, paso in enumerate(path['desglose_pasos'], 1):\n",
    "                            print(f\"         Paso {step_idx}: {paso['de']} ‚Üí {paso['a']}\")\n",
    "                            print(f\"            X={paso['valor_X']:.10f}, Importaciones={paso['importaciones_totales']:.10f}\")\n",
    "                            print(f\"            T = {paso['valor_X']:.10f} / {paso['importaciones_totales']:.10f} = {paso['T_valor']:.10f}\")\n",
    "                        \n",
    "                        # Producto final\n",
    "                        formula_prod = ' √ó '.join([f'{p[\"T_valor\"]:.10f}' for p in path['desglose_pasos']])\n",
    "                        print(f\"         PRODUCTO = {formula_prod} = {path['fuerza']:.10f}\")\n",
    "                    \n",
    "                    if len(lx_paths_sorted) > 3:\n",
    "                        print(f\"\\n      ... y {len(lx_paths_sorted)-3} m√°s\")\n",
    "                \n",
    "                print(f\"\\n   ‚ûú Suma L={L}: {di_lx:.10f}\")\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"RESUMEN FINAL\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        indirect = total_dependency - direct_dependency\n",
    "        print(f\"   Dependencia DIRECTA:        {direct_dependency:.10f} ({100*direct_dependency/total_dependency if total_dependency > 0 else 0:.1f}%)\")\n",
    "        print(f\"   Dependencia INDIRECTA:      {indirect:.10f} ({100*indirect/total_dependency if total_dependency > 0 else 0:.1f}%)\")\n",
    "        print(f\"   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
    "        print(f\"   ‚ïë DEPENDENCIA TOTAL:  {total_dependency:.10f} ‚ïë\")\n",
    "        print(f\"   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
    "        \n",
    "        print(f\"\\nDesglose por longitud de camino:\")\n",
    "        for L, dep in sorted(dependencies_by_length.items()):\n",
    "            pct = 100*dep/total_dependency if total_dependency > 0 else 0\n",
    "            print(f\"   L={L}: {dep:.10f} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "AN√ÅLISIS TRAZABLE DE DEPENDENCIA COMERCIAL CON DESGLOSE DE FUERZAS\n",
      "====================================================================================================\n",
      "\n",
      "üìä CONTEXTO:\n",
      "   Industria:       Accumulators primary cells and batteries\n",
      "   Exportador:      CHN\n",
      "   Importador:      ESP\n",
      "   Valor comercio:  1,912.42\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "MATRIZ DE TRANSICI√ìN T\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "T[a,b] = (flujo de a hacia b) / (suma total de importaciones de b)\n",
      "Dimensiones: 232 pa√≠ses √ó 232 pa√≠ses\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "C√ÅLCULO DE DEPENDENCIA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "1Ô∏è‚É£  DEPENDENCIA DIRECTA (L=1):\n",
      "   F√≥rmula: X[41,67] / Œ£(importaciones de 67)\n",
      "   Numerador:   1912.4212646484\n",
      "   Denominador: 3196.0346393585\n",
      "   ‚ûú Resultado: 0.5983731344\n",
      "\n",
      "2Ô∏è‚É£  DEPENDENCIA INDIRECTA (L=2):\n",
      "   Caminos evaluados: 230 (intermediarios posibles)\n",
      "   Top intermediarios CON DESGLOSE DE FUERZAS:\n",
      "\n",
      "      1. DEU (Fuerza: 0.0364495768)\n",
      "         ‚îî‚îÄ PASO 1: CHN ‚Üí DEU\n",
      "            X = 9105.5048828125\n",
      "            Importaciones totales de DEU = 20034.1172943115\n",
      "            T = 9105.5048828125 / 20034.1172943115 = 0.4544999287\n",
      "         ‚îî‚îÄ PASO 2: DEU ‚Üí ESP\n",
      "            X = 256.3127136230\n",
      "            Importaciones totales de ESP = 3196.0346393585\n",
      "            T = 256.3127136230 / 3196.0346393585 = 0.0801971013\n",
      "         ‚îî‚îÄ FUERZA = 0.4544999287 √ó 0.0801971013 = 0.0364495768\n",
      "\n",
      "      2. CZE (Fuerza: 0.0328392651)\n",
      "         ‚îî‚îÄ PASO 1: CHN ‚Üí CZE\n",
      "            X = 2201.5561523438\n",
      "            Importaciones totales de CZE = 4325.4879837036\n",
      "            T = 2201.5561523438 / 4325.4879837036 = 0.5089728975\n",
      "         ‚îî‚îÄ PASO 2: CZE ‚Üí ESP\n",
      "            X = 206.2102508545\n",
      "            Importaciones totales de ESP = 3196.0346393585\n",
      "            T = 206.2102508545 / 3196.0346393585 = 0.0645206558\n",
      "         ‚îî‚îÄ FUERZA = 0.5089728975 √ó 0.0645206558 = 0.0328392651\n",
      "\n",
      "      3. HUN (Fuerza: 0.0188234779)\n",
      "         ‚îî‚îÄ PASO 1: CHN ‚Üí HUN\n",
      "            X = 510.8468933105\n",
      "            Importaciones totales de HUN = 2297.4138002396\n",
      "            T = 510.8468933105 / 2297.4138002396 = 0.2223573713\n",
      "         ‚îî‚îÄ PASO 2: HUN ‚Üí ESP\n",
      "            X = 270.5576477051\n",
      "            Importaciones totales de ESP = 3196.0346393585\n",
      "            T = 270.5576477051 / 3196.0346393585 = 0.0846541663\n",
      "         ‚îî‚îÄ FUERZA = 0.2223573713 √ó 0.0846541663 = 0.0188234779\n",
      "\n",
      "      4. KOR (Fuerza: 0.0127366603)\n",
      "         ‚îî‚îÄ PASO 1: CHN ‚Üí KOR\n",
      "            X = 5736.2036132812\n",
      "            Importaciones totales de KOR = 6095.2675018311\n",
      "            T = 5736.2036132812 / 6095.2675018311 = 0.9410913650\n",
      "         ‚îî‚îÄ PASO 2: KOR ‚Üí ESP\n",
      "            X = 43.2548942566\n",
      "            Importaciones totales de ESP = 3196.0346393585\n",
      "            T = 43.2548942566 / 3196.0346393585 = 0.0135339254\n",
      "         ‚îî‚îÄ FUERZA = 0.9410913650 √ó 0.0135339254 = 0.0127366603\n",
      "\n",
      "      5. FRA (Fuerza: 0.0111993657)\n",
      "         ‚îî‚îÄ PASO 1: CHN ‚Üí FRA\n",
      "            X = 1038.0091552734\n",
      "            Importaciones totales de FRA = 3366.9492645264\n",
      "            T = 1038.0091552734 / 3366.9492645264 = 0.3082936729\n",
      "         ‚îî‚îÄ PASO 2: FRA ‚Üí ESP\n",
      "            X = 116.1021575928\n",
      "            Importaciones totales de ESP = 3196.0346393585\n",
      "            T = 116.1021575928 / 3196.0346393585 = 0.0363269397\n",
      "         ‚îî‚îÄ FUERZA = 0.3082936729 √ó 0.0363269397 = 0.0111993657\n",
      "\n",
      "      ... y 10 m√°s\n",
      "\n",
      "   ‚ûú Suma L=2: 0.1622898360\n",
      "\n",
      "3Ô∏è‚É£  DEPENDENCIA INDIRECTA (L=3):\n",
      "   Combinaciones evaluadas: 26335\n",
      "   Caminos significativos encontrados: 9\n",
      "   Top caminos CON DESGLOSE:\n",
      "\n",
      "      1. CHN ‚Üí DEU ‚Üí HUN ‚Üí ESP\n",
      "         Fuerza: 0.0039590121\n",
      "         Paso 1: CHN ‚Üí DEU\n",
      "            X=9105.5048828125, Importaciones=20034.1172943115\n",
      "            T = 9105.5048828125 / 20034.1172943115 = 0.4544999287\n",
      "         Paso 2: DEU ‚Üí HUN\n",
      "            X=236.3980560303, Importaciones=2297.4138002396\n",
      "            T = 236.3980560303 / 2297.4138002396 = 0.1028974650\n",
      "         Paso 3: HUN ‚Üí ESP\n",
      "            X=270.5576477051, Importaciones=3196.0346393585\n",
      "            T = 270.5576477051 / 3196.0346393585 = 0.0846541663\n",
      "         PRODUCTO = 0.4544999287 √ó 0.1028974650 √ó 0.0846541663 = 0.0039590121\n",
      "\n",
      "      2. CHN ‚Üí DEU ‚Üí ITA ‚Üí ESP\n",
      "         Fuerza: 0.0029769861\n",
      "         Paso 1: CHN ‚Üí DEU\n",
      "            X=9105.5048828125, Importaciones=20034.1172943115\n",
      "            T = 9105.5048828125 / 20034.1172943115 = 0.4544999287\n",
      "         Paso 2: DEU ‚Üí ITA\n",
      "            X=738.2092285156, Importaciones=3670.6607780457\n",
      "            T = 738.2092285156 / 3670.6607780457 = 0.2011107191\n",
      "         Paso 3: ITA ‚Üí ESP\n",
      "            X=104.0924530029, Importaciones=3196.0346393585\n",
      "            T = 104.0924530029 / 3196.0346393585 = 0.0325692506\n",
      "         PRODUCTO = 0.4544999287 √ó 0.2011107191 √ó 0.0325692506 = 0.0029769861\n",
      "\n",
      "      3. CHN ‚Üí KOR ‚Üí POL ‚Üí ESP\n",
      "         Fuerza: 0.0026923102\n",
      "         Paso 1: CHN ‚Üí KOR\n",
      "            X=5736.2036132812, Importaciones=6095.2675018311\n",
      "            T = 5736.2036132812 / 6095.2675018311 = 0.9410913650\n",
      "         Paso 2: KOR ‚Üí POL\n",
      "            X=571.8668823242, Importaciones=3504.4097614288\n",
      "            T = 571.8668823242 / 3504.4097614288 = 0.1631849359\n",
      "         Paso 3: POL ‚Üí ESP\n",
      "            X=56.0305290222, Importaciones=3196.0346393585\n",
      "            T = 56.0305290222 / 3196.0346393585 = 0.0175312646\n",
      "         PRODUCTO = 0.9410913650 √ó 0.1631849359 √ó 0.0175312646 = 0.0026923102\n",
      "\n",
      "      ... y 6 m√°s\n",
      "\n",
      "   ‚ûú Suma L=3: 0.0338318462\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "RESUMEN FINAL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Dependencia DIRECTA:        0.5983731344 (75.3%)\n",
      "   Dependencia INDIRECTA:      0.1961216823 (24.7%)\n",
      "   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "   ‚ïë DEPENDENCIA TOTAL:  0.7944948166 ‚ïë\n",
      "   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "Desglose por longitud de camino:\n",
      "   L=1: 0.5983731344 (75.3%)\n",
      "   L=2: 0.1622898360 (20.4%)\n",
      "   L=3: 0.0338318462 (4.3%)\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analizar una dependencia espec√≠fica\n",
    "trace = analizar_dependencia_trazable(\n",
    "    matrices_comercio,\n",
    "    industry=\"Accumulators primary cells and batteries\",           # Nombre de la industria\n",
    "    exportador_iso3=\"CHN\",            # C√≥digo ISO3 del exportador\n",
    "    importador_iso3=\"ESP\",            # C√≥digo ISO3 del importador\n",
    "    max_possible_length=3,\n",
    "    path_strength_threshold=0.001,\n",
    "    apply_cleanup=True,  # ‚Üê Ahora limpia igual que el original\n",
    "    verbose=True                      # Imprime an√°lisis detallado\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos intermediarios_globales.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ intermediarios_globales guardado en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\intermediarios_globales.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame vac√≠o para almacenar los resultados\n",
    "intermediarios_globales = []\n",
    "\n",
    "# Recorrer los resultados de cada industria\n",
    "for industry, data in all_results.items():\n",
    "    # Obtener los resultados de intermediarios para esta industria\n",
    "    for country, freq, strength, score in data['results']['intermediary_centrality']:\n",
    "        intermediarios_globales.append({\n",
    "            'industry': industry,\n",
    "            'country': country,\n",
    "            'frequency_total': freq,\n",
    "            'strength_total': strength,\n",
    "            'global_score': score\n",
    "        })\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_intermediarios = pd.DataFrame(intermediarios_globales)\n",
    "\n",
    "# Guardar el DataFrame como Parquet\n",
    "output_path = Path.cwd().parent.parent / \"data\" / \"processed\" / \"dependencias_consolidadas\" / \"intermediarios_globales.parquet\"\n",
    "df_intermediarios.to_parquet(output_path, index=False)\n",
    "print(f\"‚úÖ intermediarios_globales guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "country_profiles.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ country_profiles guardado en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\country_profiles.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista para almacenar los perfiles de los pa√≠ses\n",
    "country_profiles = []\n",
    "\n",
    "# Recorrer los resultados de cada industria\n",
    "for industry, data in all_results.items():\n",
    "    # Obtener los resultados de dependencias por pa√≠s\n",
    "    for country in data['results']['dependencies']:\n",
    "        # Agregar el perfil del pa√≠s\n",
    "        country_profiles.append({\n",
    "            'industry': industry,\n",
    "            'country': country['importador'],\n",
    "            'vulnerability': country.get('dependencia_total', 0),\n",
    "            'importance': country.get('dependencia_total', 0),\n",
    "            'num_suppliers': country.get('num_suppliers', 0)\n",
    "        })\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_country_profiles = pd.DataFrame(country_profiles)\n",
    "\n",
    "# Guardar como Parquet\n",
    "output_path = Path.cwd().parent.parent / \"data\" / \"processed\" / \"dependencias_consolidadas\" / \"country_profiles.parquet\"\n",
    "df_country_profiles.to_parquet(output_path, index=False)\n",
    "print(f\"‚úÖ country_profiles guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relaciones_criticas.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ relaciones_criticas guardado en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\relaciones_criticas.parquet\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar las relaciones cr√≠ticas\n",
    "relaciones_criticas = []\n",
    "\n",
    "# Recorrer los resultados de cada industria\n",
    "for industry, data in all_results.items():\n",
    "    # Obtener las relaciones cr√≠ticas de esta industria\n",
    "    crits = identify_critical_trade_relationships(data['results'], threshold=0.7, min_paths=3)\n",
    "    for c in crits:\n",
    "        c['industry'] = industry\n",
    "        relaciones_criticas.append(c)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_relaciones_criticas = pd.DataFrame(relaciones_criticas)\n",
    "\n",
    "# Guardar como Parquet\n",
    "output_path = Path.cwd().parent.parent / \"data\" / \"processed\" / \"dependencias_consolidadas\" / \"relaciones_criticas.parquet\"\n",
    "df_relaciones_criticas.to_parquet(output_path, index=False)\n",
    "print(f\"‚úÖ relaciones_criticas guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caminos_significativos.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ caminos_significativos guardado en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\caminos_significativos.parquet\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los caminos significativos\n",
    "caminos_significativos = []\n",
    "\n",
    "# Recorrer los resultados de cada industria\n",
    "for industry, data in all_results.items():\n",
    "    # Obtener los caminos significativos de esta industria\n",
    "    for path in data['results']['critical_paths']:\n",
    "        caminos_significativos.append({\n",
    "            'industry': industry,\n",
    "            'exportador': path['exportador'],\n",
    "            'importador': path['importador'],\n",
    "            'intermediarios': path['intermediarios'],\n",
    "            'fuerza': path['fuerza'],\n",
    "            'longitud': path['longitud']\n",
    "        })\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_caminos_significativos = pd.DataFrame(caminos_significativos)\n",
    "\n",
    "# Guardar como Parquet\n",
    "output_path = Path.cwd().parent.parent / \"data\" / \"processed\" / \"dependencias_consolidadas\" / \"caminos_significativos.parquet\"\n",
    "df_caminos_significativos.to_parquet(output_path, index=False)\n",
    "print(f\"‚úÖ caminos_significativos guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar que all_results est√© disponible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ all_results guardado en: c:\\Users\\Usuario\\Documents\\Github\\Seguridad Economica\\data\\processed\\dependencias_consolidadas\\all_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Guardar all_results como archivo .pkl\n",
    "import pickle\n",
    "\n",
    "# Aseg√∫rate de que 'all_results' se haya creado antes de esta celda\n",
    "pkl_path = Path.cwd().parent.parent / \"data\" / \"processed\" / \"dependencias_consolidadas\" / \"all_results.pkl\"\n",
    "with open(pkl_path, \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"‚úÖ all_results guardado en: {pkl_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dependencias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
